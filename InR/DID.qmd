---
title: "Diferencias en Diferencias"
subtitle: "Maestría en Economía Uninorte"
author: "Carlos Andrés Yanes"
date: "2024-08-24"
format:
    pdf: default
    html: 
      self-contained: true
      grid: 
        margin-width: 350px
execute: 
  warning: false
reference-location: margin
citation-location: margin
bibliography: refs.bib
---

# Introducción

Seguimos trabajando el *ejemplo* de Nessa, Ali, and Abdul-Hakim (2012) para el análisis del impacto Programa de Microcréditos realizado en Bangladesh para 1998.

El método de **Diferencias en Diferencias (DID)** es una técnica econométrica ampliamente utilizada para evaluar el **impacto causal** de políticas públicas, programas o intervenciones que se implementan en ciertas unidades (como individuos, empresas, regiones, etc.) pero no en otras. Este método se basa en comparar la evolución de un resultado de interés entre un grupo tratado (que recibe la intervención) y un grupo de control (que no la recibe) *antes* y *después* del tratamiento.

El enfoque DID asume que, en ausencia del tratamiento, la diferencia en las tendencias del resultado entre los grupos tratado y de control habría permanecido constante. De esta manera, cualquier desviación de esta tendencia paralela se atribuye al efecto causal del tratamiento.

En economía, el método de Diferencias en Diferencias es particularmente útil cuando los experimentos aleatorios no son factibles o éticos, y permite controlar por factores no observados que podrían influir en los resultados, siempre que estos factores sean constantes en el tiempo. Esta técnica ha sido utilizada en estudios que analizan desde el impacto de cambios en las políticas fiscales y laborales hasta los efectos de programas educativos y de salud, convirtiéndose en una herramienta clave para el análisis de políticas públicas.

## Preparación

Antes de implementar el código de estimación, es crucial preparar la base de datos asegurando que las variables relevantes estén correctamente definidas y limpiadas. Esto implica verificar que las variables de tratamiento y resultado estén codificadas adecuadamente, que las covariables no presenten valores faltantes, y que los pesos muestrales, si son aplicables, estén correctamente asignados. Además, es esencial que los datos estén en el formato adecuado para ser utilizados en los modelos estadísticos, lo que incluye transformar variables según sea necesario y asegurarse de que todas las observaciones relevantes sean incluidas en el análisis.

## Estipulación de la base

Vamos a cargar los paquetes a utilizar en esta ocasión

```{r}
library(pacman)
p_load(survey, foreign, haven, tidyverse, huxtable, dplyr, Matching, ggplot2, plm, car)
```

El paso a seguir es cargar la base de datos (formato stata) a R.

```{r}
datacon9198 <- read.dta("hh_9198.dta")
```



### Transformación y adecuación de la data

Vamos a simular para tratar de acondicionar los datos de los microcreditos
```{r}
# Creamos los ajustes
datacon9198 <- datacon9198 %>%
  mutate(
    exptot0 = ifelse(year == 0, exptot, 0)
  ) %>%
  group_by(nh) %>%
  mutate(
    exptot91 = max(exptot0)
  ) %>%
  ungroup() %>%
  filter(year == 1) %>%
  mutate(
    lexptot91 = log(1 + exptot91),
    lexptot98 = log(1 + exptot),
    lexptot9891 = lexptot98 - lexptot91
  )

head(datacon9198)

```

## Para grupo Masculino y femenino

Vamos a montar una data de tal manera que jugamos con las variables para que por grupos tengamos una dummy para $T=1$ periodo posterior y $T=0$ como el anterior

```{r}
datacon9198 <- datacon9198 %>%
  mutate(
    lexptot = log(1 + exptot),
    lnland = log(1 + hhland / 100),
    dmmfd1 = ifelse(dmmfd == 1 & year == 1, 1, 0),
    dfmfd1 = ifelse(dfmfd == 1 & year == 1, 1, 0)
  ) %>%
  group_by(nh) %>%
  mutate(
    dmmfd98 = max(dmmfd1),
    dfmfd98 = max(dfmfd1)
  ) %>%
  ungroup() %>%
  mutate(
    dmmfdyr = dmmfd98 * year,
    dfmfdyr = dfmfd98 * year
  )

head(datacon9198)

```

Ya con la estructura de datos preparada vamos a los modelos a estimar.

```{r}
basico <- lm(lexptot ~ year + dfmfd98 + dfmfdyr, data = datacon9198)
huxreg(basico)
```

## Modelo de Panel con Efecto fijo

```{r}
library(pglm)
model_pglm <- pglm(lexptot ~ year + dfmfdyr + dfmfd98, data = datacon9198, 
                   family = gaussian, model = "within", index = "nh")
summary(model_pglm)

```


```r
# Convertir los datos a un formato de panel
datacon9198_panel <- pdata.frame(datacon9198, index = c("nh"))

# Estimar el modelo de efectos fijos
lm_panel <- plm(lexptot ~ year + dfmfdyr + dfmfd98, 
                data = datacon9198_panel, 
                model = "within")
# Resumen del modelo
summary(lm_panel)
```




  #Check for multicolinearity
  
  sqrt(vif(lm))     #Error in vif.default(lm) : there are aliased coefficients in the model
  
  # Contains multicollinearity
  check <- alias(lm)   # Notice that dfmfd98 = -1, therefore highly correlated with dfmfdyr

  # Remove dfmfd98
  lm <- lm(lexptot ~ year + dfmfdyr + factor(nh), data = datacon9198)
  sqrt(vif(lm))
  
  # Output is fine now, so can proceed

  # GVIF       Df GVIF^(1/(2*Df))
  # year       1.453455  1.00000        1.205593
  # dfmfdyr    1.764237  1.00000        1.328246
  # factor(nh) 1.414214 28.72281        1.000210

  # Second method for testing for multicollinearity kappa()
  test <- model.matrix(~ year + dfmfdyr + dfmfd98 + factor(nh), data = datacon9198)
  kappa(test)   # Output : 2.017073e+16

  #### Because of an extra large kappa, there is collinearity in our model and should be dealt with
  #### conditional number must be less than 30
  
summary(lm)

# Using plm for fixed-effect



###############
# PSM with DD
###############

# Data setup

datacon9198 <- read.csv("Data/hh_9198.csv")
datacon9198 <- mutate(datacon9198, lnland = log(1 + hhland / 100))
datacon9198 <- mutate(datacon9198, dfmfd1=ifelse(dfmfd == 1 & year == 1, 1, 0))
datacon9198 <- group_by(datacon9198,nh) %>%
  mutate(dfmfd98 = max(dfmfd1))
datacon9198 <- filter(datacon9198, year == 0)
datacon9198$X <- 1:nrow(datacon9198)

# First Regression (Unbalanced)

des1 <- svydesign(id = ~X,  weights = ~weight, data = datacon9198)
prog.lm <- svyglm(dfmfd98 ~ sexhead + agehead + educhead + lnland + vaccess + pcirr + rice + wheat + milk + oil, 
                  design=des1, family = quasibinomial(link = "probit"))   

X <- prog.lm$fitted
Tr <- datacon9198$dfmfd

m.out <- Match(Tr = Tr, X = X, caliper = 0.01)
summary(m.out)

MatchBalance(dfmfd98 ~ sexhead + agehead + educhead + lnland + vaccess + pcirr + rice + wheat + milk + oil, data = datacon9198, nboots = 1000)

#Graph density of propensity scores
fit <- prog.lm$data
fit$fvalues <- prog.lm$fitted.values 

fit.control <- filter(fit, dfmfd == 0)
fit.treated <- filter(fit, dfmfd == 1)

ggplot() + 
  geom_density(aes(x=fit.control$fvalues, linetype = '2')) +
  geom_density(aes(x=fit.treated$fvalues, linetype = '3')) +
  xlim(-.3,1) +
  xlab("") +
  scale_linetype_discrete(name = "", labels = c("Control", "Treated")) +
  ggtitle("Control and Treated Densities")


# Build data frame with ps and nh, then drop ps not matched
ps_dropped <- m.out$index.dropped
ps_datacon9198 <- data.frame(psm = prog.lm$fitted.values)
ps_datacon9198$nh <- prog.lm$data$nh
ps_datacon9198 <- ps_datacon9198[-ps_dropped,]
rownames(ps_datacon9198) <- NULL

#Merge to original data frame by nh
datacon9198 <- read.csv("Data/hh_9198.csv")
psm_datacon9198 <- right_join(datacon9198, ps_datacon9198, by = "nh")

# Re-estimate baseline model with matched data set

psm_datacon9198 <- mutate(psm_datacon9198, lexptot = log(1 + exptot))
psm_datacon9198 <- mutate(psm_datacon9198, lnland = log(1 + hhland / 100))
psm_datacon9198 <- mutate(psm_datacon9198, dfmfd1=ifelse(dfmfd == 1 & year == 1, 1, 0))
psm_datacon9198 <- group_by(psm_datacon9198,nh) %>%
  mutate(dfmfd98 = max(dfmfd1))
psm_datacon9198 <- mutate(psm_datacon9198, dfmfdyr = dfmfd98*year)
psm_datacon9198 <- ungroup(psm_datacon9198)

# Re-estimate Basic Model

lm <- lm(lexptot ~ year + dfmfd98 + dfmfdyr, data = psm_datacon9198)
summary(lm)

# Create Analytical Weights

psm_datacon9198$a_weight <- 1
psm_datacon9198$a_weight <- ifelse(psm_datacon9198$dfmfd == 0, psm_datacon9198$psm/(1-psm_datacon9198$psm), 1)

# Re-estimate with analytical weights

lm <- lm(lexptot ~ year + dfmfd98 + dfmfdyr, data = psm_datacon9198, weights = a_weight)
summary(lm)


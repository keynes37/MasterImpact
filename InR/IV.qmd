---
title: "Variables Instrumentales"
subtitle: "Maestría en Economía Uninorte"
author: "Carlos Andrés Yanes"
date: "2024-08-24"
format:
    pdf: default
    html: 
      self-contained: true
      grid: 
        margin-width: 350px
execute: 
  warning: false
reference-location: margin
citation-location: margin
bibliography: refs.bib
---

# Preambulo

Los modelos de **variables instrumentales** (IV) son una técnica econométrica crucial cuando se enfrentan problemas de endogeneidad en la estimación de relaciones causales. En la evaluación de impacto, la endogeneidad surge cuando una o más variables explicativas están correlacionadas con el término de error, lo que sesga los estimadores y dificulta identificar efectos causales verdaderos.

### ¿Qué es la endogeneidad?
La endogeneidad puede surgir por varias razones, como la presencia de variables omitidas, la simultaneidad, o el error de medición. Por ejemplo, al evaluar el impacto de la educación en los ingresos, es posible que factores no observados como la habilidad innata o el entorno familiar influyan tanto en la educación como en los ingresos, generando una correlación entre la educación y el término de error.

### ¿Qué son las Variables Instrumentales?
Las variables instrumentales se utilizan para resolver este problema. Una variable instrumental es una variable que está correlacionada con la variable explicativa endógena pero que no está correlacionada con el término de error. En otras palabras, el instrumento afecta el resultado solo a través de su impacto en la variable endógena.

Supongamos que estamos interesados en medir el impacto de una intervención educativa en los salarios futuros. Si los individuos que eligen participar en la intervención son aquellos más motivados o con más recursos, la simple estimación de una regresión lineal podría sobreestimar el impacto de la intervención debido a la selección no aleatoria. Aquí es donde un buen instrumento es vital.

Si encontramos un instrumento válido, como una política de expansión educativa que no está directamente relacionada con los salarios futuros, podemos utilizarlo para estimar el impacto causal de la educación en los ingresos, aislando el efecto de la endogeneidad.

::: {.callout-tip}
## Cuidado
La base de datos para este modulo solo será enviada por correo electronico a los estudiantes del curso de Econometría de la Universidad del Norte
:::

## Datos

* Fuente original es de Jeffrey R. Kling (2001).

* El artículo se llama: "Interpreting Instrumental Variables Estimates of the Returns to Schooling". Journal of Business and Economic Statistics, 19, 358-364.

* Tiene que ver con los retornos de la educación[^1]
[^1]: Hemos insistido en los temas de educación ya que existe una amplia literatura en la implementación de este tipo de **instrumentos** para una correcta estimación

## Limpiando el Environment de R

```{r}
rm(list = ls())
```

## Preparación del entorno para ejecución

Primero que nada preparar los paquetes que se van a usar para realizar el ejercicio. Estos permitiran usar las `funciones` para los cálculos pertinentes

```{r}
library(pacman)
p_load(lmtest, foreign, haven, tidyverse, stargazer, dplyr, estimatr, ggplot2, sandwich)
```

### Cargar la base de datos
Del archivo proporcionado y utilizando a `haven` procedemos a importar la base
```{r}
base.ed <- read_dta("Returnseducational.dta")
head(base.ed)
```

### Etiquetas

La base de datos de acuerdo a las columnas de datos podemos decir de cada una de ellas lo siguiente:

| Variable  | Tipo  | Etiqueta de la Variable                     |
|-----------|-------|---------------------------------------------|
| wage76    | float | Salario en el '76                           |
| grade76   | float | Nivel educativo en el '76                   |
| col4      | float | Si hay alguna universidad de 4 años cerca   |
| age76     | float | Edad en el '76 (edad66 + 10)                |


## Estadistica

```{r}
summary(base.ed[c("wage76", "grade76", "col4", "age76")])
```

### Correlación

Por un momento miremos la correlación que existe entre este par de variables

```{r}
# Correlación
cor(base.ed$grade76, base.ed$col4)
```

# Primer modelo de estimación
Vamos a mirar el resultado de la estimación

```{r}
ols_model <- lm(wage76 ~ grade76 + age76, base.ed)
coeftest(ols_model, vcov = vcovHC(ols_model, type = "HC"))
```

Denotando que el <span style="color:red">Número de años que llevaba aprobados</span>
hasta el año 76 genera un impacto en el salario bastante significativo. A medida que esto aumenta en un año adicional el salario tambien aumenta.


# Guardar el modelo MCO
A continuación con el objetivo de hacer una comparación adecuada de modelos vamos a ir guardando las salidas correspondientes en objetos para darle una forma mas adecuada y con ellos tener una mejor interpretabilidad

```{r}
ols_model <- lm(wage76 ~ grade76 + age76, data = base.ed)
```

# Modelo IV usando la función ivreg del paquete AER
Empecemos a instrumentar, la idea parte de decir que el hecho de que una universidad este cerca a un individuo incide en su escolaridad o tomar una elección de hacerlo pero no tiene nada que ver con el salario que percibe. La edad tambien se convierte en otro instrumento clave. La edad es un factor decisorio para de alguna manera tomar la decisión de escolarizarse y solo en algunas veces puede incidir algo en el salario debido a politicas que puedan tener las empresas pero no deberia darnos problemas adicionales.

```{r}
library(AER)
iv_model <- ivreg(wage76 ~ grade76 + age76 | col4 + age76, data = base.ed)
summary(iv_model, vcov = sandwich)
```

Los resultados son homocedasticos al aplicar la corrección tipo `sandwich` para corregir problemas de varianza no constante.

# Tabla de comparaciones entre MCO y IV
Vamos hacer la comparación entre modelos para ver que diferencias tienen los resultados. El paquete `stargazer` ayuda a darle visibilidad a los datos

```{r}
library(stargazer)
stargazer(ols_model, iv_model, type = "text", 
          keep = c("grade76"), digits = 4, 
          se = list(coeftest(ols_model, vcov = vcovHC(ols_model, type = "HC"))[, 2],
                    sqrt(diag(vcovHC(iv_model, type = "HC")))),
          dep.var.labels = "Salario en el 76'", covariate.labels = "Años aprobados 76'")
```

Note la diferencia que existe en el estimador IV. Al parecer estábamos **sobreestimando** el efecto que tiene la educación en el salario de los individuos.

## Estimación del estimador IV en dos etapas
Miremos esto por fases o etapas[^2]
[^2]: Son los comunmente conocidos Modelos 2LS (Two least Square) o Bi-etapicos.

### Primera etapa: regresión OLS para obtener la predicción
Corremos un modelo donde se intenta explicar la educación con los controles sugeridos
```{r}
first_stage <- lm(grade76 ~ col4 + age76, data = base.ed )
base.ed$grade76hat <- predict(first_stage)
```

## Segunda etapa: regresión OLS con el valor predicho
Estimamos el modelo pero con la educación estimada $(\hat{educ})$

```{r}
ols_two_stage <- lm(wage76 ~ grade76hat + age76, data = base.ed)
coeftest(ols_two_stage, vcov = vcovHC(ols_two_stage, type = "HC"))
```

## Repetir el análisis con más controles
Recordemos que podemos adherir un número mayor de controles sobre nuestra estimación

```{r}
exog_regressors <- c("black", "south76", "smsa76", "reg2", "reg3", "reg4", "reg5", "reg6", "reg7", "reg8", "reg9", 
                     "smsa66", "momdad14", "sinmom14", "nodaded", "nomomed", "daded", "momed", 
                     "famed1", "famed2", "famed3", "famed4", "famed5", "famed6", "famed7", "famed8")

# Resumir las variables seleccionadas
summary(data[c("wage76", "grade76", "exp76", "expsq76", "col4", "age76", "agesq76", exog_regressors)])
```

### Modelo MCO con más controles

```r
ols_model_controls <- lm(wage76 ~ grade76+., data = base.ed, subset = exog_regressors)
coeftest(ols_model_controls, vcov = vcovHC(ols_model_controls, type = "HC"))
```



### Modelo IV con más controles

```r
iv_model_controls <- ivreg(wage76 ~ grade76 + . | col4 + ., data = base.ed, subset = exog_regressors)
summary(iv_model_controls, vcov = sandwich)
```



# Tabla de comparaciones entre OLS y IV con más controles
Una salida general a todo esto que hemos realizado nos da como resultado:
```r
stargazer(ols_model_controls, iv_model_controls, type = "text", 
          keep = c("grade76"), digits = 4, 
          dep.var.labels = "wage76", covariate.labels = "grade76")
```

# Diagnóstico de instrumentos débiles: correlación y regresión
Para verificar relevancia de los instrumentos
```r
cor(base.ed$grade76, base.ed$col4)
first_stage_diagnostic <- lm(grade76 ~ col4 + age76, data = base.ed)
summary(first_stage_diagnostic)
```

## Test de instrumentos débiles (Anderson-Rubin Wald test)
El test de Anderson-Rubin evalúa si los coeficientes de las variables instrumentales en la regresión auxiliar (donde las variables instrumentales se utilizan para predecir la variable endógena) son estadísticamente diferentes de cero. Si se rechaza la hipótesis nula, esto indica que los instrumentos son relevantes y, por lo tanto, no son débiles.

```r
iv_test <- summary(iv_model_controls, vcov = sandwich)
waldtest(iv_test)
```




# Agradecimientos
Mucho de este trabajo se debe a los artículos, recursos (free commons) y material del Profesor Colin Cameron, autor del libro: Microeconometrics Using Stata.

**Carlos Yanes Guerra | Departamento de Economía | Universidad del Norte**


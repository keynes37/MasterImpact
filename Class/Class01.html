<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Econometría</title>
    <meta charset="utf-8" />
    <meta name="author" content="Carlos A. Yanes Guerra" />
    <script src="libs/header-attrs-2.26/header-attrs.js"></script>
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <script src="libs/xaringanExtra_fit-screen-0.2.6/fit-screen.js"></script>
    <script src="libs/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="libs/shareon-1.4.1/shareon.min.css" rel="stylesheet" />
    <script src="libs/shareon-1.4.1/shareon.min.js"></script>
    <link href="libs/xaringanExtra-shareagain-0.2.6/shareagain.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-shareagain-0.2.6/shareagain.js"></script>
    <script src="libs/kePrint-0.0.1/kePrint.js"></script>
    <link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="my-css.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">





name: xaringan-title
class: inverse, left, bottom
background-image: url(images/beach1.jpg)
background-size: cover

# **Econometría**
----

## **&lt;br/&gt; El asunto de Regresión**

### Carlos A. Yanes Guerra
### 2023-I




---
# Todo sobre regresión

--

### *Econometría*

**El objetivo?** Identificar el efecto de la variable de tratamiento `\(D\)` en una variable resultado `\(Y\)`..super[.hi-pink[&lt;span&gt;&amp;#8224;&lt;/span&gt;]]

--

- **Cómo?** Eliminando/minimizando de alguna manera el .hi-pink[sesgo de selección].

.footnote[.super[.hi-pink[&lt;span&gt;&amp;#8224;&lt;/span&gt;]] Los otros objetivos? Pronosticar valores futuros de variables de resultados clave, como el desempleo, el PIB, la retención de clientes, *etc.*]

--

### **Análisis de regresión**

&gt; Conjunto de procesos estadísticos para cuantificar la relación entre una variable dependiente (por ejemplo, un resultado) y una o varias variables independientes (por ejemplo, un tratamiento o una variable de control).

---
# Todo sobre regresión

--

### **Análisis de regresión**

--

Los economistas recurren a menudo al análisis de regresión para realizar diversas comparaciones estadísticas.

- Puede facilitar las comparaciones "a igualdad de condiciones" 
- Puede eliminar el .hi-pink[sesgo de selección] **controlando explícitamente** .hi-pink[variables de control] 
- Si no se controlan las variables de control .mono[--&gt;] .hi-pink[sesgo de variables omitidas].

--

**Nuestro objetivo?** Aprender a interpretar los resultados de un análisis de regresión.

1. **Interpretación literal**
    - Interpretar el tamaño y la significación estadística de las estimaciones de los coeficientes de regresión..
    - Saber como usar una tabla de regresión.

2. **Interpretación a gran escala** 
    - ¿Qué implican las estimaciones sobre los efectos de un tratamiento?     
    - ¿Debemos fiarnos de las estimaciones? ¿Reflejan una relación causal? 

---
class: inverse, middle

# Regresión lineal simple
&lt;img src="images/lognig.png" width="280" /&gt;

---
# Regresión lineal simple

&lt;img src="Class01_files/figure-html/simple-1.svg" style="display: block; margin: auto;" /&gt;

---
count: false
# Regresión lineal simple

&lt;img src="Class01_files/figure-html/simple_reg-1.svg" style="display: block; margin: auto;" /&gt;

---
# Regresión lineal simple

### **Modelo**

--

Podemos expresar la relación entre .hi-purple[variable de resultado] y .hi-green[variable de tratamiento] como una función lineal:

$$
 \color{#9370DB}{Y_i} = \beta_0 + \beta_1~\color{#007935}{D_i} + \varepsilon_i
$$

- La parte `\(i\)` corresponde a los individuos (corte transversal).
- `\(\beta_0\)` .mono[=] término de __intercepto__ o constante.
- `\(\beta_1\)` .mono[=] la __pendiente__.
    - Pensemos por ahora que `\(D_i\)` puede tomar distintos valores mas allá que los binarios (*p.e.,* 0 o 1).
- `\(\varepsilon_i\)` .mono[=] término del __error__ (residuo).

.footnote[
_Simple_ .mono[=] solo una variable independiente.
]

---
# Regresión lineal simple

### **Modelo**

--

El término del .hi[intercepto] nos dice el valor esperado de `\(Y_i\)` cuando la explicativa es `\(D_i = 0\)`. 

$$
 Y_i = \color{#e64173}{\beta_0} + \beta_1 ~ D_i + \varepsilon_i
$$

Parte de la recta de regresión, pero casi nunca es objeto de **análisis**.

- En la práctica, omitir el intercepto sesgaría las estimaciones del coeficiente de la pendiente&amp;mdash;el objeto que realmente nos importa.

---
# Regresión lineal simple

### **Modelo**

--

El término de .hi[la pendiente] nos dice los cambios esperados en `\(Y_i\)` cuando `\(D_i\)` se incrementa en una unidad. 

$$
 Y_i = \beta_0 + \color{#e64173}{\beta_1} ~ D_i + \varepsilon_i
$$

"Un incremento en una unidad de `\(D_i\)` *esta asociado con* un incremento de la unidad `\(\color{#e64173}{\beta_1}\)` en `\(Y_i\)`."

--

Bajo ciertos supuestos de MCO (fuertes) (*p.e.,* no hay sesgo de selección) podemos decir que, `\(\color{#e64173}{\beta_1}\)` representa el efecto causal de `\(D_i\)` en `\(Y_i\)`.

- "Un incremento de una unidad en `\(D_i\)` *conduce* a un incremento de `\(\color{#e64173}{\beta_1}\)` en `\(Y_i\)`."
- De otra manera, solo seria la _asociación lineal_ de `\(D_i\)` _con_ `\(Y_i\)`, representando una correlación no causal.

---
# Regresión lineal simple

### **Modelo**

--

El .hi[termino del error] nos recuerda que `\(D_i\)` no es la única variable que tiene efectos sobre `\(Y_i\)`. 

$$
 Y_i = \beta_0 + \beta_1 ~ D_i + \color{#e64173}{\varepsilon_i}
$$

--

este término nos muestra que otros factores/variables tienen efecto en `\(Y_i\)`.

- **Así que?** Si algunos de esos .hi-slate[factores] .ul[influyen] en `\(D_i\)`, entonces el .hi-orange[sesgo de variable omitida] contaminará las **estimaciones** del coeficiente de la pendiente.

---
# Regresión lineal simple

### **Ejemplo**

.pull-left[
**P:** Como la .hi[atención] tiene efectos en el rendimiento académico?

Tratando de dar respuesta a esto, vamos a estimar un modelo de **regresión** que nos va a capturar esto
`$$\text{Final}_i = \beta_0 + \beta_1~\text{Atención}_i + \varepsilon_i$$`

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Parámetros &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; (1) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Intercepto &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-weight: bold;"&gt; 56.82 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-weight: bold;"&gt; (2.19) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Atención &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-weight: bold;"&gt; 0.3 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-weight: bold;"&gt; (0.08) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
.center[*Errores estándar en paréntesis.*]
]
.pull-right[
&lt;img src="Class01_files/figure-html/attend_1_plot-1.svg" style="display: block; margin: auto;" /&gt;
]

---
# Regresión lineal simple

### **Ejemplo**



.pull-left[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de Policías.sub[*i*]]]
&lt;img src="Class01_files/figure-html/campus_crime_1_plot-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[
**P:** El número de policias reducen el crimen en los campus universitarios?

- Qué nos dice la pendiente?
]

---
count: false
# Regresión lineal simple

### **Ejemplo**

.pull-left[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/campus_crime_2_plot-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[
**P:** El número de policias reducen el crimen en los campus universitarios?

- Qué nos dice la pendiente?


**P:** Significa que los policias *causan* el crimen en el campus!?

- Por qué o Por qué no?
]

---
count: false
# Regresión lineal simple

### **Ejemplo**

.pull-left[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/campus_crime_3_plot-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[
**P:** El número de policias reducen el crimen en los campus universitarios?

- Qué nos dice la pendiente?


**P:** Significa que los policias *causan* el crimen en el campus!?

- Por qué o Por qué no?

.footnote[Para mirar la discusión de los efectos causales puede  mirar un debate en el asunto del crimen y los arrestos&amp;mdash;y como los efectos incluso varian por raza&amp;mdash; se encuentra en [episode 55](https://www.probablecausation.com/podcasts/episode-55-morgan-williams-jr) Es un podcast de la página [*Posible causalidad*](https://www.probablecausation.com/)]
]


---
# Regresión lineal simple

### **Ejemplo**

.pull-left[
**P:** De donde surge la .blue[línea] de regresión?
]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-2-1.svg" style="display: block; margin: auto;" /&gt;
]

---
count: false
# Regresión lineal simple

### **Estimación**

.pull-left[
**P:** De donde surge la .blue[línea] de regresión? &lt;br&gt;
**R/:** Un algoritmo llamado  **Mínimos cuadrados ordinarios (MCO)**.

]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-3-1.svg" style="display: block; margin: auto;" /&gt;
]

---
count: false
# Regresión lineal simple

### **Estimación**

.pull-left[
**P:** De donde surge la .blue[línea] de regresión? &lt;br&gt;
**R/:** Un algoritmo llamado  **Mínimos cuadrados ordinarios (MCO)**.

**Como funciona el MCO?**


]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-4-1.svg" style="display: block; margin: auto;" /&gt;
]

---
count: false
# Regresión lineal simple

### **Estimación**

.pull-left[
**P:** De donde surge la .blue[línea] de regresión? &lt;br&gt;
**R/:** Un algoritmo llamado  **Mínimos cuadrados ordinarios (MCO)**.

**Como funciona el MCO?**

- Cada  "linea de ajuste" produce un .hi-pink[residuo].
- Los residuos son .mono[=] Los valores reales .mono[-] .hi-purple[predichos]

]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de  Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-5-1.svg" style="display: block; margin: auto;" /&gt;
]

---
# Regresión lineal simple

### **Estimación**

.pull-left[
**P:** De donde surge la .blue[línea] de regresión? &lt;br&gt;
**R/:** Un algoritmo llamado  **Mínimos cuadrados ordinarios (MCO)**.

**Como funciona el MCO?**

- Algunas lineas de los ajustados generan mayores residuos que otros 



]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 58.2 .mono[+] -2.2 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-7-1.svg" style="display: block; margin: auto;" /&gt;
]

---
count: false
# Regresión lineal simple

### **Estimación**

.pull-left[
**P:** De donde surge la .blue[línea] de regresión? &lt;br&gt;
**R/:** Un algoritmo llamado  **Mínimos cuadrados ordinarios (MCO)**.

**Como funciona el MCO?**

- Algunas lineas de los ajustados generan mayores residuos que otros 



]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 20.5 .mono[+] 3.15 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-9-1.svg" style="display: block; margin: auto;" /&gt;
]

---
count: false
# Regresión lineal simple

### **Estimación**

.pull-left[
**P:** De donde surge la .blue[linea] de regresión? &lt;br&gt;
**R/:** Un algoritmo llamado  **Mínimos cuadrados ordinarios (MCO)**.

**Como funciona el MCO?**

- Algunas lineas de los ajustados generan mayores residuos que otros 



]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 1.3 .mono[+] 0.75 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-11-1.svg" style="display: block; margin: auto;" /&gt;
]

---
# Regresión lineal simple

### **Estimación**

.pull-left[
**P:** De donde surge la .blue[linea] de regresión? &lt;br&gt;
**R/:** Un algoritmo llamado  **Mínimos cuadrados ordinarios (MCO)**.

**Como funciona el MCO?**

- La "mejor línea de ajuste" es aquella que **minimiza** la **suma de los residuos al cuadrado**.
- **P:** Por qué al cuadrado?

]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-12-1.svg" style="display: block; margin: auto;" /&gt;
]

---
count: false
# Regresión lineal simple

### **Estimación**

.pull-left[
**P:** De donde surge la .blue[linea] de regresión? &lt;br&gt;
**R/:** Un algoritmo llamado  **Mínimos cuadrados ordinarios (MCO)**.

**Como funciona el MCO?**

- La "mejor linea de ajuste" es aquella que **minimiza** la **suma de los residuos al cuadrado**.
- **P:** Por qué al cuadrado?
- Usando matemáticas y mirando algunos lineamientos del profesor.

]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-13-1.svg" style="display: block; margin: auto;" /&gt;
]


---
# Regresión lineal simple

### **Estimación**

.pull-left[
**P:** De donde surge la .blue[linea] de regresión? &lt;br&gt;
**R/:** Un algoritmo llamado  **Mínimos cuadrados ordinarios (MCO)**.

**Como funciona el MCO?**


- **"Mínimos?"** Minimize that sum.
- **"Cuadrados?"** Suma al cuadrado de los residuos.
- **"Ordinarios?"** La forma mas tradicional de resolver el algoritmo.

]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-14-1.svg" style="display: block; margin: auto;" /&gt;
]

---
class: inverse, middle

# Retornos de la educación
&lt;img src="images/lognig.png" width="280" /&gt;

---
# Regresión lineal simple

### **Ejemplo: Retornos de la educación**

La inversión óptima en educación por parte de estudiantes, padres y legisladores depende en parte del *retorno monetario de la educación*.

--

.hi-purple[Pensemos en un experimento:]
- Realizamos una asignacióna aleatoria.
- Dado un año adicional de educación.
- Cuanto aumenta el nivel de ingreso de una persona?

El cambio en sus ingresos describe el .hi-slate[efecto causal] de la educación sobre los ingresos.

---
# Regresión lineal simple

### **Ejemplo: Retornos de la educación**



.pull-left[
.center[.purple[Ingresos.sub[*i*] .mono[=] 146.95 .mono[+] 60.21 Escolaridad.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-16-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[
**P:** ¿Cuánto dinero extra puede esperar un trabajador de esta muestra dado un año adicional de educación?

- Como saberlo?
]

---
count: false
# Regresión lineal simple

### **Ejemplo: Retornos de la educación**

.pull-left[
.center[.purple[Ingresos.sub[*i*] .mono[=] 146.95 .mono[+] 60.21 Escolaridad.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-17-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[
**P:** ¿Cuánto dinero extra puede esperar un trabajador de esta muestra dado un año adicional de educación?

- Como saberlo?

**P:** ¿Representa esta cifra el rendimiento causal de un año adicional de educación?

- ¿Qué otras variables podrían estar impulsando la relación?
]

---
class: inverse, middle

# Haciendo Ajustes
&lt;img src="images/lognig.png" width="280" /&gt;

---
# Haciendo Ajustes

.pull-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-18-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[
Podemos producir una línea ajustada estimando una regresión de un resultado sobre un tratamiento: `$$Y_i = \beta_0 + \beta_1~D_i + \varepsilon_i$$`

`\(\beta\)` describe cómo cambia el resultado, *en promedio*, cuando cambia el tratamiento.

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Parámetro &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; (1) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Intercepto &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-weight: bold;"&gt; 1.22 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-weight: bold;"&gt; (0.18) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Tratamiento &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-weight: bold;"&gt; 0.56 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-weight: bold;"&gt; (0.08) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
.center[*Errores estandar en parentesis.*]
]

---
# Haciendo Ajustes

.pull-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-20-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[

Sin embargo, nos puede preocupar que una tercera variable `\(W_i\)` confunda nuestra estimación del efecto del tratamiento sobre el resultado.
]

---
# Haciendo Ajustes

.pull-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-21-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[

Si existen datos sobre la variable de control adicional, pueden añadirse al modelo de regresión: `$$Y_i = \beta_0 + \beta_1~D_i + \gamma_i~W_i + \varepsilon_i$$`
]

**P:** ¿Cómo "ajusta" MCO la inclusión de esa variable?

---
count: false
# Haciendo Ajustes

.pull-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-22-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[

Si existen datos sobre la variable de control adicional, pueden añadirse al modelo de regresión: `$$Y_i = \beta_0 + \beta_1~D_i + \gamma_i~W_i + \varepsilon_i$$`

**P:** ¿Cómo "ajusta" MCO la inclusión de esa variable?

- **Paso 1:** Averiguar qué diferencias en D se explican por W.
]



---
# Haciendo Ajustes

.pull-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-23-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[

Si existen datos sobre la variable de control adicional, pueden añadirse al modelo de regresión: `$$Y_i = \beta_0 + \beta_1~D_i + \gamma_i~W_i + \varepsilon_i$$`

**P:** ¿Cómo "ajusta" MCO la inclusión de esa variable?

- **Paso 2:** Remover las diferencias de D explicadas por W.
]

---
# Haciendo Ajustes

.pull-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-24-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[

Si existen datos sobre la variable de control adicional, pueden añadirse al modelo de regresión: `$$Y_i = \beta_0 + \beta_1~D_i + \gamma_i~W_i + \varepsilon_i$$`

**P:** ¿Cómo "ajusta" MCO la inclusión de esa variable?

- **Paso 3:** Miramos que diferencias de Y son explicadas por W
]



---
# Haciendo Ajustes

.pull-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-25-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[

Si existen datos sobre la variable de control adicional, pueden añadirse al modelo de regresión: `$$Y_i = \beta_0 + \beta_1~D_i + \gamma_i~W_i + \varepsilon_i$$`

**P:** ¿Cómo "ajusta" MCO la inclusión de esa variable?

- **Paso 4:** Removemos las diferencias de Y que son explicadas por W
]



---
# Haciendo Ajustes

.pull-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-26-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[

Si existen datos sobre la variable de control adicional, pueden añadirse al modelo de regresión: `$$Y_i = \beta_0 + \beta_1~D_i + \gamma_i~W_i + \varepsilon_i$$`

**P:** ¿Cómo "ajusta" MCO la inclusión de esa variable?

- **Paso 5:** Establecemos una regresión que se ajusta a los datos con que contamos

]

---
# Haciendo Ajustes

.pull-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-27-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[

Si la co-variable existe y se puede vincular, podemos entonces adherirla al modelo de regresión: `$$Y_i = \beta_0 + \beta_1~D_i + \gamma_i~W_i + \varepsilon_i$$`

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Parameter &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; (1) &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; (2) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Intercepto &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;"&gt; 1.22 &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-weight: bold;"&gt; 0.9 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;"&gt; (0.18) &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-weight: bold;"&gt; (0.1) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Tratamiento &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;"&gt; 0.56 &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-weight: bold;"&gt; -0.42 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;"&gt; (0.08) &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-weight: bold;"&gt; (0.07) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Covariable &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-weight: bold;"&gt; 3.91 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-weight: bold;"&gt; (0.2) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
.center[*Errores estandar en parentesis.*]
]

---
class: inverse, middle

# Sesgo de variables omitidas
&lt;img src="images/lognig.png" width="280" /&gt;


---
# Sesgo de variables omitidas

--

### **Ejemplo: Retornos de la educación**

.pull-left[
&lt;br&gt;
&lt;table&gt;
&lt;caption&gt;Resultado: Ganancia Semanal&lt;/caption&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Parámetro &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; 1 &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; 2 &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Intercepto &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-weight: bold;"&gt; 146.95 &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;"&gt; -128.89 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-weight: bold;"&gt; (77.72) &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;"&gt; (92.18) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Años de escolaridad &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-weight: bold;"&gt; 60.21 &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;"&gt; 42.06 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-weight: bold;"&gt; (5.70) &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;"&gt; (6.55) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Prueba IQ Score (Puntos) &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-weight: bold;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;"&gt; 5.14 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-weight: bold;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;"&gt; (0.96) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
.center[*Errores estándar en paréntesis.*]
]

.pull-right[

]

---
count: false
# Sesgo de variables omitidas

### **Ejemplo: Retornos de la educación**

.pull-left[
&lt;br&gt;
&lt;table&gt;
&lt;caption&gt;Resultado: Ganancia Semanal&lt;/caption&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Parámetro &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; 1 &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; 2 &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Intercepto &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;"&gt; 146.95 &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-weight: bold;"&gt; -128.89 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;"&gt; (77.72) &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-weight: bold;"&gt; (92.18) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Años de escolaridad &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;"&gt; 60.21 &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-weight: bold;"&gt; 42.06 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;"&gt; (5.70) &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-weight: bold;"&gt; (6.55) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Prueba IQ Score (Puntos) &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;line-height: 110%;font-weight: bold;"&gt; 5.14 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: rgba(39, 40, 34, 255) !important;color: rgba(194, 190, 190, 255) !important;line-height: 110%;font-weight: bold;"&gt; (0.96) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
.center[*Errores estándar en paréntesis.*]
]

--

.pull-right[
&lt;br&gt; &lt;br&gt;

.orange[Sesgo] por omitir el score de IQ 
&lt;br&gt; `\(\quad\)` .mono[=] .pink["Corto"] .mono[-] .purple["largo"]
&lt;br&gt; `\(\quad\)` .mono[=] .pink[60.21] .mono[-] .purple[42.06]
&lt;br&gt; `\(\quad\)` .mono[=] .orange[18.15]

La primera regresión atribuye erróneamente parte de la influencia de la inteligencia a la educación.
]

---
# Sesgo de variables omitidas

.more-left[
&lt;img src="Class01_files/figure-html/venn2-1.svg" style="display: block; margin: auto;" /&gt;
]

.less-right[

.hi-purple[Y] .mono[=] Resultado

.hi-green[D] .mono[=] Tratamiento

.hi-orange[W] .mono[=] Variable Omitida

Si .hi-orange[W] esta correlacionada con ambas .hi-green[D] y la variable .hi-purple[Y] .mono[--&gt;] el sesgo de variable omitida .mono[--&gt;] el método de regresión falla en aislar el efecto causal de la variable de tratamiento .hi-green[D] en .hi-purple[Y].
]

---
# Sesgo de variables omitidas

.more-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-31-1.svg" style="display: block; margin: auto;" /&gt;
]

.less-right[

.hi-purple[Y] .mono[=] Resultado

.hi-green[D] .mono[=] Tratamiento

.hi-orange[W] .mono[=] Variable Omitida

Si .hi-orange[W] esta correlacionada con ambas .hi-green[D] y la variable .hi-purple[Y] .mono[--&gt;] el sesgo de variable omitida .mono[--&gt;] el método de regresión falla en aislar el efecto causal de la variable de tratamiento .hi-green[D] en .hi-purple[Y].

]

---
class: inverse, middle

# Elementos adicionales e inferencia
&lt;img src="images/lognig.png" width="280" /&gt;

---
# Estimador

--

El modelo de regresión simple, obtendremos los estimadores `\(\hat{\beta}_0\)` y `\(\hat{\beta}_1\)` que minimiza la suma de los residuos al cuadrado (SSE), _p.e._,

--

`$$\min_{\hat{\beta}_0,\, \hat{\beta}_1} \text{SSE}$$`

--

Vamos a conocer que:

`$$\text{SSE} = \sum_i e_i^2$$`

--

La referencia es que los residuos `\(e_i\)` salen del modelo estimado o valor predicho de la .hi[dependiente] `\(\hat{y}\)` y de la variable resultado `\(y\)`.

--

$$
`\begin{aligned}
  e_i^2 &amp;= \left( y_i - \hat{y}_i \right)^2 = \left( y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i \right)^2 \\
  &amp;= y_i^2 - 2 y_i \hat{\beta}_0 - 2 y_i \hat{\beta}_1 x_i + \hat{\beta}_0^2 + 2 \hat{\beta}_0 \hat{\beta}_1 x_i + \hat{\beta}_1^2 x_i^2
\end{aligned}`
$$

--

**Recuerde:** Minimizar una función multivariada requiere 
1. La primera derivada (La condición de *1.super[er]-orden*) y, 
2. La condición de *2.super[do]-orden* o (concavidad).

---
# Estimador

--

Debemos **minimizar la SSE**

`$$\text{SSE} = \sum_{i=1}^{n} e_i^2 = \sum_{i=1}^n\left( y_i^2 - 2 y_i \hat{\beta}_0 - 2 y_i \hat{\beta}_1 x_i + \hat{\beta}_0^2 + 2 \hat{\beta}_0 \hat{\beta}_1 x_i + \hat{\beta}_1^2 x_i^2 \right)$$`

--

Dadas las condiciones de primer orden de .hi[minimización], realizamos la primera derivada de SSE con respecto a `\(\hat{\beta}_0\)` como de `\(\hat{\beta}_1\)`.

--

$$
`\begin{aligned}
  \dfrac{\partial \text{SSE}}{\partial \hat{\beta}_0} &amp;= \sum_i \left( 2 \hat{\beta}_0 + 2 \hat{\beta}_1 x_i - 2 y_i \right) = 2n \hat{\beta}_0 + 2 \hat{\beta}_1 \sum_i x_i - 2 \sum_i y_i \\
  &amp;= 2n \hat{\beta}_0 + 2n \hat{\beta}_1 \overline{x} - 2n \overline{y}
\end{aligned}`
$$

donde `\(\overline{x} = \frac{\sum x_i}{n}\)` y `\(\overline{y} = \frac{\sum y_i}{n}\)` son las medias muestrales de `\(x\)` e `\(y\)` (tamaño `\(n\)`).

---
# Estimador

--

Las condiciones de primer orden establecen que las derivadas son iguales a cero, por lo que:

--

`$$\dfrac{\partial \text{SSE}}{\partial \hat{\beta}_0} = 2n \hat{\beta}_0 + 2n \hat{\beta}_1 \overline{x} - 2n \overline{y} = 0$$`

--

`$$\hat{\beta}_0 = \overline{y} - \hat{\beta}_1 \overline{x}$$`

--

<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:red;overflow:visible;position:relative;"><path d="M464 256A208 208 0 1 1 48 256a208 208 0 1 1 416 0zM0 256a256 256 0 1 0 512 0A256 256 0 1 0 0 256zM294.6 135.1c-4.2-4.5-10.1-7.1-16.3-7.1C266 128 256 138 256 150.3V208H160c-17.7 0-32 14.3-32 32v32c0 17.7 14.3 32 32 32h96v57.7c0 12.3 10 22.3 22.3 22.3c6.2 0 12.1-2.6 16.3-7.1l99.9-107.1c3.5-3.8 5.5-8.7 5.5-13.8s-2-10.1-5.5-13.8L294.6 135.1z"/></svg> Este .hi[estimador] viene a ser la diferencia entre los promedios de nuestras variables dependientes e independientes teniendo presente el efecto de `\(\hat{\beta}_1\)`.

--

Ahora solo nos falta por hallar `\(\hat{\beta}_1\)`.

---
# Estimador

--

Hay que tomar la derivada de SSE con respecto a `\(\hat{\beta}_1\)`

--

$$
`\begin{aligned}
  \dfrac{\partial \text{SSE}}{\partial \hat{\beta}_1} &amp;= \sum_i \left( 2 \hat{\beta}_0 x_i + 2 \hat{\beta}_1 x_i^2 - 2 y_i x_i \right) = 2 \hat{\beta}_0 \sum_i x_i + 2 \hat{\beta}_1 \sum_i x_i^2 - 2 \sum_i y_i x_i \\
  &amp;= 2n \hat{\beta}_0 \overline{x} + 2 \hat{\beta}_1 \sum_i x_i^2 - 2 \sum_i y_i x_i
\end{aligned}`
$$

todo igual a cero (condición de primer-orden, de nuevo)

--

`$$\dfrac{\partial \text{SSE}}{\partial \hat{\beta}_1} = 2n \hat{\beta}_0 \overline{x} + 2 \hat{\beta}_1 \sum_i x_i^2 - 2 \sum_i y_i x_i = 0$$`

--

y sustituimos `\(\hat{\beta}_0\)`, _p.e._, `\(\hat{\beta}_0 = \overline{y} - \hat{\beta}_1 \overline{x}\)`. Así,

--

$$
 2n \left(\overline{y} - \hat{\beta}_1 \overline{x}\right) \overline{x} + 2 \hat{\beta}_1 \sum_i x_i^2 - 2 \sum_i y_i x_i = 0
$$

---
# Estimador

--

Ya después de jugar con tanta álgebra:

--

$$2n \left(\overline{y} - \hat{\beta}_1 \overline{x}\right) \overline{x} + 2 \hat{\beta}_1 \sum_i x_i^2 - 2 \sum_i y_i x_i = 0 $$

--

a multiplicar

--

`$$2n \overline{y}\,\overline{x} - 2n \hat{\beta}_1 \overline{x}^2 + 2 \hat{\beta}_1 \sum_i x_i^2 - 2 \sum_i y_i x_i = 0$$`

--

`$$\implies 2 \hat{\beta}_1 \left( \sum_i x_i^2 - n \overline{x}^2 \right) = 2 \sum_i y_i x_i - 2n \overline{y}\,\overline{x}$$`

--

$$ \implies \hat{\beta}_1 = \dfrac{\sum_i y_i x_i - 2n \overline{y}\,\overline{x}}{\sum_i x_i^2 - n \overline{x}^2} = \dfrac{\sum_i (x_i - \overline{x})(y_i - \overline{y})}{\sum_i (x_i - \overline{x})^2} $$

---
# Estimador

--

Hecho!!

Ahora tenemos los estimadores MCO (encantadores) para la pendiente

--

`$$\hat{\beta}_1 = \dfrac{\sum_i (x_i - \overline{x})(y_i - \overline{y})}{\sum_i (x_i - \overline{x})^2}$$`
--

Para el intercepto o `\(\beta_{0}\)`

`$$\hat{\beta}_0 = \overline{y} - \hat{\beta}_1 \overline{x}$$`

--

Ahora **ya saben de dónde** sale formalmente la parte de *mínimos cuadrados* de MCO.

---
class: inverse, middle

# Función de esperanza condicional
&lt;img src="images/lognig.png" width="280" /&gt;

---
# Función de esperanza condicional

--

### La función de expectativa condicional

--

Decimos que `\(Y\)` es una variable aleatoria y `\(X=(X_1,X_2,...,X_k)\)` un vector de variables aleatorias explicativas. Si `\(E(|Y|)&lt;\infty\)` entonces hay una función `\(\mu:\mathbb{R}^k \to \mathbb{R}\)` tal que

--

`\begin{equation}
\tag{1}
E(Y|X_1,X_2,...,X_k)=\mu(X_1,X_2,...,X_k)
\end{equation}`

A esto lo llamamos la función de expectativa condicional y nos determina como cambia el valor medio de `\(Y\)` cuando cambian los elementos de `\(X\)`. 

Definimos el error de la expectativa condicional como la diferencia entre `\(Y\)` y el valor de la función de expectativa condicional evaluada en `\(X\)`

`\begin{equation}
\tag{2}
e=Y-\mu(X)
\end{equation}`

---
# Función de esperanza condicional

--

Luego por construcción

`\begin{equation}
\tag{2}
Y=\mu(X)+e
\end{equation}`

--

También, por construcción, tenemos que la expectativa condicional del error es cero

`\begin{align}
E(e|X)&amp;=E(Y-\mu(X)|X)\\
&amp;=E(Y|X)-E(\mu(X)|X)\\
&amp;=\mu(X)-\mu(X)\\
&amp;=0
\end{align}`

--

Y al usar la ley de expectativas iteradas, `\(E(E(Y|X))=E(Y)\)` tenemos que 

`\begin{equation}
E(e)=E(E(Y|X))=E(0)=0
\end{equation}`

--

Ahora, podemos especificar la función de expectativa condicional de la siguiente manera

`\begin{equation}
\mu(X)=\beta_0+\beta_1X_1+\beta_2X_2+...+\beta_kX_k
\end{equation}`

---
# Función de esperanza condicional

--

De donde podemos como cambios marginales en los regresores `\(X\)` impactan en la expectativa condicional de la variable de resultado `\(Y\)`. Si la variable `\(X_1\)` es continua, entonces

--

`\begin{equation}
\dfrac{\partial E(Y|X)}{\partial{X_1}}=\beta_1
\end{equation}`

Si la variable `\(X_1\)` es discreta y toma los valores `\(0\)` y `\(1\)`, entonces tenemos que

--

`\begin{equation}
E(Y|X_1=1)-E(Y|X_1=0)=\beta_1
\end{equation}`

En otras palabras, los parámetros recogen el cambio en la expectativa condicional de `\(Y\)` atribuible a `\(X\)`, dado que todo lo demás está constante. Todo lo demás significa todas las demás variables explícitamente incorporadas en el modelo. Ahora, si usamos la forma lineal en `\((2)\)` tenemos que

--

`\begin{equation}
Y=\beta_0+\beta_1X_1+\beta_2X_2+...+\beta_kX_k+u
\end{equation}`

De donde podemos concluir que los parámetros capturan el cambio en el valor actual de `\(Y\)` atribuible al cambio en la independiente, solo si el error `\(e\)` no está afectado por el regresor que se modifica. Esto nos lleva a la discusión sobre efectos causales

---


&lt;img src="Class01_files/figure-html/fig_cef_dist-1.svg" style="display: block; margin: auto;" /&gt;
---
&lt;img src="Class01_files/figure-html/fig_cef-1.svg" style="display: block; margin: auto;" /&gt;
---
&lt;img src="Class01_files/figure-html/fig_cef_only-1.svg" style="display: block; margin: auto;" /&gt;


---
class: inverse
# Bibliografía

<svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M96 0C43 0 0 43 0 96V416c0 53 43 96 96 96H384h32c17.7 0 32-14.3 32-32s-14.3-32-32-32V384c17.7 0 32-14.3 32-32V32c0-17.7-14.3-32-32-32H384 96zm0 384H352v64H96c-17.7 0-32-14.3-32-32s14.3-32 32-32zm32-240c0-8.8 7.2-16 16-16H336c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16zm16 48H336c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16s7.2-16 16-16z"/></svg> Angrist, J. D., &amp; Pischke, J. S. (2009). *Mostly harmless econometrics: An empiricist's companion*. Princeton university press.

<svg aria-hidden="true" role="img" viewBox="0 0 384 512" style="height:1em;width:0.75em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm97 289c9.4-9.4 9.4-24.6 0-33.9s-24.6-9.4-33.9 0L79 303c-9.4 9.4-9.4 24.6 0 33.9l48 48c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-31-31 31-31zM257 255c-9.4-9.4-24.6-9.4-33.9 0s-9.4 24.6 0 33.9l31 31-31 31c-9.4 9.4-9.4 24.6 0 33.9s24.6 9.4 33.9 0l48-48c9.4-9.4 9.4-24.6 0-33.9l-48-48z"/></svg> Rubin, E. (2021) *Econometrics Lectures class*.

<svg aria-hidden="true" role="img" viewBox="0 0 384 512" style="height:1em;width:0.75em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm97 289c9.4-9.4 9.4-24.6 0-33.9s-24.6-9.4-33.9 0L79 303c-9.4 9.4-9.4 24.6 0 33.9l48 48c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-31-31 31-31zM257 255c-9.4-9.4-24.6-9.4-33.9 0s-9.4 24.6 0 33.9l31 31-31 31c-9.4 9.4-9.4 24.6 0 33.9s24.6 9.4 33.9 0l48-48c9.4-9.4 9.4-24.6 0-33.9l-48-48z"/></svg> Raze, K. (2022) *Labor Economics Lectures class*.

<svg aria-hidden="true" role="img" viewBox="0 0 576 512" style="height:1em;width:1.12em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg> Angrist, J. (2022) *Mastering Econometrics* [Con Acceso abril 2022](https://mru.org/mastering-econometrics-joshua-angrist).

<svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M96 0C43 0 0 43 0 96V416c0 53 43 96 96 96H384h32c17.7 0 32-14.3 32-32s-14.3-32-32-32V384c17.7 0 32-14.3 32-32V32c0-17.7-14.3-32-32-32H384 96zm0 384H352v64H96c-17.7 0-32-14.3-32-32s14.3-32 32-32zm32-240c0-8.8 7.2-16 16-16H336c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16zm16 48H336c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16s7.2-16 16-16z"/></svg> Wooldridge, J. M. (2015). *Introductory econometrics: A modern approach*. Cengage learning.


---
name: adios
class: middle, inverse

.pull-left[
# **¡Gracias!**
&lt;br/&gt;
## Econometría I

### Seguimos aprendiendo
]

.pull-right[
.right[
&lt;img style="border-radius: 50%;"
src="https://avatars.githubusercontent.com/u/39503983?v=4"
width="150px" /&gt;

[<svg aria-hidden="true" role="img" viewBox="0 0 640 512" style="height:1em;width:1.25em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M579.8 267.7c56.5-56.5 56.5-148 0-204.5c-50-50-128.8-56.5-186.3-15.4l-1.6 1.1c-14.4 10.3-17.7 30.3-7.4 44.6s30.3 17.7 44.6 7.4l1.6-1.1c32.1-22.9 76-19.3 103.8 8.6c31.5 31.5 31.5 82.5 0 114L422.3 334.8c-31.5 31.5-82.5 31.5-114 0c-27.9-27.9-31.5-71.8-8.6-103.8l1.1-1.6c10.3-14.4 6.9-34.4-7.4-44.6s-34.4-6.9-44.6 7.4l-1.1 1.6C206.5 251.2 213 330 263 380c56.5 56.5 148 56.5 204.5 0L579.8 267.7zM60.2 244.3c-56.5 56.5-56.5 148 0 204.5c50 50 128.8 56.5 186.3 15.4l1.6-1.1c14.4-10.3 17.7-30.3 7.4-44.6s-30.3-17.7-44.6-7.4l-1.6 1.1c-32.1 22.9-76 19.3-103.8-8.6C74 372 74 321 105.5 289.5L217.7 177.2c31.5-31.5 82.5-31.5 114 0c27.9 27.9 31.5 71.8 8.6 103.9l-1.1 1.6c-10.3 14.4-6.9 34.4 7.4 44.6s34.4 6.9 44.6-7.4l1.1-1.6C433.5 260.8 427 182 377 132c-56.5-56.5-148-56.5-204.5 0L60.2 244.3z"/></svg> Syllabus/ Curso](https://ignaciomsarmiento.github.io/teaching/UniNorte/Syllabus__Ciencia_de_Datos_TDE.pdf)&lt;br/&gt;
[<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> @keynes37](https://twitter.com/keynes37)&lt;br/&gt;
[<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M64 112c-8.8 0-16 7.2-16 16v22.1L220.5 291.7c20.7 17 50.4 17 71.1 0L464 150.1V128c0-8.8-7.2-16-16-16H64zM48 212.2V384c0 8.8 7.2 16 16 16H448c8.8 0 16-7.2 16-16V212.2L322 328.8c-38.4 31.5-93.7 31.5-132 0L48 212.2zM0 128C0 92.7 28.7 64 64 64H448c35.3 0 64 28.7 64 64V384c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64V128z"/></svg> cayanes@uninorte.edu.co](mailto:cayanes@uninorte.edu.co)
]
]

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>

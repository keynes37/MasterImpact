<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Econometría</title>
    <meta charset="utf-8" />
    <meta name="author" content="Carlos A. Yanes Guerra" />
    <script src="libs/header-attrs-2.11/header-attrs.js"></script>
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <script src="libs/xaringanExtra_fit-screen-0.2.6/fit-screen.js"></script>
    <script src="libs/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="libs/shareon-1.4.1/shareon.min.css" rel="stylesheet" />
    <script src="libs/shareon-1.4.1/shareon.min.js"></script>
    <link href="libs/xaringanExtra-shareagain-0.2.6/shareagain.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-shareagain-0.2.6/shareagain.js"></script>
    <script src="libs/kePrint-0.0.1/kePrint.js"></script>
    <link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="my-css.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">





name: xaringan-title
class: inverse, left, bottom
background-image: url(images/beach1.jpg)
background-size: cover

# **Econometría**
----

## **&lt;br/&gt; El asunto de Regresión**

### Carlos A. Yanes Guerra
### 2023-I




---
# Todo sobre regresión

--

### *Econometría*

**El objetivo?** Identificar el efecto de la variable de tratamiento `\(D\)` en una variable resultado `\(Y\)`..super[.hi-pink[&lt;span&gt;&amp;#8224;&lt;/span&gt;]]

--

- **Cómo?** Eliminando/minimizando de alguna manera el .hi-pink[sesgo de selección].

.footnote[.super[.hi-pink[&lt;span&gt;&amp;#8224;&lt;/span&gt;]] Los otros objetivos? Pronosticar valores futuros de variables de resultados clave, como el desempleo, el PIB, la retención de clientes, *etc.*]

--

### **Análisis de regresión**

&gt; Conjunto de procesos estadísticos para cuantificar la relación entre una variable dependiente (por ejemplo, un resultado) y una o varias variables independientes (por ejemplo, un tratamiento o una variable de control).

---
# Todo sobre regresión

--

### **Análisis de regresión**

--

Los economistas recurren a menudo al análisis de regresión para realizar diversas comparaciones estadísticas.

- Puede facilitar las comparaciones "a igualdad de condiciones" 
- Puede eliminar el .hi-pink[sesgo de selección] **controlando explícitamente** .hi-pink[variables de control] 
- Si no se controlan las variables de control .mono[--&gt;] .hi-pink[sesgo de variables omitidas].

--

**Nuestro objetivo?** Aprender a interpretar los resultados de un análisis de regresión.

1. **Interpretación literal**
    - Interpretar el tamaño y la significación estadística de las estimaciones de los coeficientes de regresión..
    - Saber como usar una tabla de regresión.

2. **Interpretación a gran escala** 
    - ¿Qué implican las estimaciones sobre los efectos de un tratamiento?     
    - ¿Debemos fiarnos de las estimaciones? ¿Reflejan una relación causal? 

---
class: inverse, middle

# Regresión lineal simple
&lt;img src="images/lognig.png" width="280" /&gt;

---
# Regresión lineal simple

&lt;img src="Class01_files/figure-html/simple-1.svg" style="display: block; margin: auto;" /&gt;

---
count: false
# Regresión lineal simple

&lt;img src="Class01_files/figure-html/simple_reg-1.svg" style="display: block; margin: auto;" /&gt;

---
# Regresión lineal simple

### **Modelo**

--

Podemos expresar la relación entre .hi-purple[variable de resultado] y .hi-green[variable de tratamiento] como una función lineal:

$$
 \color{#9370DB}{Y_i} = \beta_0 + \beta_1~\color{#007935}{D_i} + \varepsilon_i
$$

- La parte `\(i\)` corresponde a los individuos (corte transversal).
- `\(\beta_0\)` .mono[=] término de __intercepto__ o constante.
- `\(\beta_1\)` .mono[=] la __pendiente__.
    - Pensemos por ahora que `\(D_i\)` puede tomar distintos valores mas allá que los binarios (*p.e.,* 0 o 1).
- `\(\varepsilon_i\)` .mono[=] término del __error__ (residuo).

.footnote[
_Simple_ .mono[=] solo una variable independiente.
]

---
# Regresión lineal simple

### **Modelo**

--

El término del .hi[intercepto] nos dice el valor esperado de `\(Y_i\)` cuando la explicativa es `\(D_i = 0\)`. 

$$
 Y_i = \color{#e64173}{\beta_0} + \beta_1 ~ D_i + \varepsilon_i
$$

Parte de la recta de regresión, pero casi nunca es objeto de **análisis**.

- En la práctica, omitir el intercepto sesgaría las estimaciones del coeficiente de la pendiente&amp;mdash;el objeto que realmente nos importa.

---
# Regresión lineal simple

### **Modelo**

--

El término de .hi[la pendiente] nos dice los cambios esperados en `\(Y_i\)` cuando `\(D_i\)` se incrementa en una unidad. 

$$
 Y_i = \beta_0 + \color{#e64173}{\beta_1} ~ D_i + \varepsilon_i
$$

"Un incremento en una unidad de `\(D_i\)` *esta asociado con* un incremento de la unidad `\(\color{#e64173}{\beta_1}\)` en `\(Y_i\)`."

--

Bajo ciertos supuestos de MCO (fuertes) (*p.e.,* no hay sesgo de selección) podemos decir que, `\(\color{#e64173}{\beta_1}\)` representa el efecto causal de `\(D_i\)` en `\(Y_i\)`.

- "Un incremento de una unidad en `\(D_i\)` *conduce* a un incremento de `\(\color{#e64173}{\beta_1}\)` en `\(Y_i\)`."
- De otra manera, solo seria la _asociación lineal_ de `\(D_i\)` _con_ `\(Y_i\)`, representando una correlación no causal.

---
# Regresión lineal simple

### **Modelo**

--

El .hi[termino del error] nos recuerda que `\(D_i\)` no es la única variable que tiene efectos sobre `\(Y_i\)`. 

$$
 Y_i = \beta_0 + \beta_1 ~ D_i + \color{#e64173}{\varepsilon_i}
$$

--

este término nos muestra que otros factores/variables tienen efecto en `\(Y_i\)`.

- **Así que?** Si algunos de esos .hi-slate[factores] .ul[influyen] en `\(D_i\)`, entonces el .hi-orange[sesgo de variable omitida] contaminará las **estimaciones** del coeficiente de la pendiente.

---
# Regresión lineal simple

### **Ejemplo**

.pull-left[
**P:** Como la .hi[atención] tiene efectos en el rendimiento académico?

Tratando de dar respuesta a esto, vamos a estimar un modelo de **regresión** que nos va a capturar esto
`$$\text{Final}_i = \beta_0 + \beta_1~\text{Atención}_i + \varepsilon_i$$`

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Parámetros &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; (1) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Intercepto &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;font-weight: bold;"&gt; 56.82 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-weight: bold;"&gt; (2.19) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Atención &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;font-weight: bold;"&gt; 0.3 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-weight: bold;"&gt; (0.08) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
.center[*Errores estándar en paréntesis.*]
]
.pull-right[
&lt;img src="Class01_files/figure-html/attend_1_plot-1.svg" style="display: block; margin: auto;" /&gt;
]

---
# Regresión lineal simple

### **Ejemplo**



.pull-left[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de Policías.sub[*i*]]]
&lt;img src="Class01_files/figure-html/campus_crime_1_plot-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[
**P:** El número de policias reducen el crimen en los campus universitarios?

- Qué nos dice la pendiente?
]

---
count: false
# Regresión lineal simple

### **Ejemplo**

.pull-left[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/campus_crime_2_plot-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[
**P:** El número de policias reducen el crimen en los campus universitarios?

- Qué nos dice la pendiente?


**P:** Significa que los policias *causan* el crimen en el campus!?

- Por qué o Por qué no?
]

---
count: false
# Regresión lineal simple

### **Ejemplo**

.pull-left[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/campus_crime_3_plot-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[
**P:** El número de policias reducen el crimen en los campus universitarios?

- Qué nos dice la pendiente?


**P:** Significa que los policias *causan* el crimen en el campus!?

- Por qué o Por qué no?

.footnote[Para mirar la discusión de los efectos causales puede  mirar un debate en el asunto del crimen y los arrestos&amp;mdash;y como los efectos incluso varian por raza&amp;mdash; se encuentra en [episode 55](https://www.probablecausation.com/podcasts/episode-55-morgan-williams-jr) Es un podcast de la página [*Posible causalidad*](https://www.probablecausation.com/)]
]


---
# Regresión lineal simple

### **Ejemplo**

.pull-left[
**P:** De donde surge la .blue[línea] de regresión?
]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-2-1.svg" style="display: block; margin: auto;" /&gt;
]

---
count: false
# Regresión lineal simple

### **Estimación**

.pull-left[
**P:** De donde surge la .blue[línea] de regresión? &lt;br&gt;
**R/:** Un algoritmo llamado  **Mínimos cuadrados ordinarios (MCO)**.

]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-3-1.svg" style="display: block; margin: auto;" /&gt;
]

---
count: false
# Regresión lineal simple

### **Estimación**

.pull-left[
**P:** De donde surge la .blue[línea] de regresión? &lt;br&gt;
**R/:** Un algoritmo llamado  **Mínimos cuadrados ordinarios (MCO)**.

**Como funciona el MCO?**


]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-4-1.svg" style="display: block; margin: auto;" /&gt;
]

---
count: false
# Regresión lineal simple

### **Estimación**

.pull-left[
**P:** De donde surge la .blue[línea] de regresión? &lt;br&gt;
**R/:** Un algoritmo llamado  **Mínimos cuadrados ordinarios (MCO)**.

**Como funciona el MCO?**

- Cada  "linea de ajuste" produce un .hi-pink[residuo].
- Los residuos son .mono[=] Los valores reales .mono[-] .hi-purple[predichos]

]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de  Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-5-1.svg" style="display: block; margin: auto;" /&gt;
]

---
# Regresión lineal simple

### **Estimación**

.pull-left[
**P:** De donde surge la .blue[línea] de regresión? &lt;br&gt;
**R/:** Un algoritmo llamado  **Mínimos cuadrados ordinarios (MCO)**.

**Como funciona el MCO?**

- Algunas lineas de los ajustados generan mayores residuos que otros 



]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 58.2 .mono[+] -2.2 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-7-1.svg" style="display: block; margin: auto;" /&gt;
]

---
count: false
# Regresión lineal simple

### **Estimación**

.pull-left[
**P:** De donde surge la .blue[línea] de regresión? &lt;br&gt;
**R/:** Un algoritmo llamado  **Mínimos cuadrados ordinarios (MCO)**.

**Como funciona el MCO?**

- Algunas lineas de los ajustados generan mayores residuos que otros 



]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 20.5 .mono[+] 3.15 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-9-1.svg" style="display: block; margin: auto;" /&gt;
]

---
count: false
# Regresión lineal simple

### **Estimación**

.pull-left[
**P:** De donde surge la .blue[linea] de regresión? &lt;br&gt;
**R/:** Un algoritmo llamado  **Mínimos cuadrados ordinarios (MCO)**.

**Como funciona el MCO?**

- Algunas lineas de los ajustados generan mayores residuos que otros 



]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 1.3 .mono[+] 0.75 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-11-1.svg" style="display: block; margin: auto;" /&gt;
]

---
# Regresión lineal simple

### **Estimación**

.pull-left[
**P:** De donde surge la .blue[linea] de regresión? &lt;br&gt;
**R/:** Un algoritmo llamado  **Mínimos cuadrados ordinarios (MCO)**.

**Como funciona el MCO?**

- La "mejor línea de ajuste" es aquella que **minimiza** la **suma de los residuos al cuadrado**.
- **P:** Por qué al cuadrado?

]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-12-1.svg" style="display: block; margin: auto;" /&gt;
]

---
count: false
# Regresión lineal simple

### **Estimación**

.pull-left[
**P:** De donde surge la .blue[linea] de regresión? &lt;br&gt;
**R/:** Un algoritmo llamado  **Mínimos cuadrados ordinarios (MCO)**.

**Como funciona el MCO?**

- La "mejor linea de ajuste" es aquella que **minimiza** la **suma de los residuos al cuadrado**.
- **P:** Por qué al cuadrado?
- Usando matemáticas y mirando algunos lineamientos del profesor.

]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-13-1.svg" style="display: block; margin: auto;" /&gt;
]


---
# Regresión lineal simple

### **Estimación**

.pull-left[
**P:** De donde surge la .blue[linea] de regresión? &lt;br&gt;
**R/:** Un algoritmo llamado  **Mínimos cuadrados ordinarios (MCO)**.

**Como funciona el MCO?**


- **"Mínimos?"** Minimize that sum.
- **"Cuadrados?"** Suma al cuadrado de los residuos.
- **"Ordinarios?"** La forma mas tradicional de resolver el algoritmo.

]
.pull-right[
.center[.purple[Crimen.sub[*i*] .mono[=] 18.41 .mono[+] 1.76 Número de Policias.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-14-1.svg" style="display: block; margin: auto;" /&gt;
]

---
class: inverse, middle

# Retornos de la educación
&lt;img src="images/lognig.png" width="280" /&gt;

---
# Regresión lineal simple

### **Ejemplo: Retornos de la educación**

La inversión óptima en educación por parte de estudiantes, padres y legisladores depende en parte del *retorno monetario de la educación*.

--

.hi-purple[Pensemos en un experimento:]
- Realizamos una asignacióna aleatoria.
- Dado un año adicional de educación.
- Cuanto aumenta el nivel de ingreso de una persona?

El cambio en sus ingresos describe el .hi-slate[efecto causal] de la educación sobre los ingresos.

---
# Regresión lineal simple

### **Ejemplo: Retornos de la educación**



.pull-left[
.center[.purple[Ingresos.sub[*i*] .mono[=] 146.95 .mono[+] 60.21 Escolaridad.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-16-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[
**P:** ¿Cuánto dinero extra puede esperar un trabajador de esta muestra dado un año adicional de educación?

- Como saberlo?
]

---
count: false
# Regresión lineal simple

### **Ejemplo: Retornos de la educación**

.pull-left[
.center[.purple[Ingresos.sub[*i*] .mono[=] 146.95 .mono[+] 60.21 Escolaridad.sub[*i*]]]
&lt;img src="Class01_files/figure-html/unnamed-chunk-17-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[
**P:** ¿Cuánto dinero extra puede esperar un trabajador de esta muestra dado un año adicional de educación?

- Como saberlo?

**P:** ¿Representa esta cifra el rendimiento causal de un año adicional de educación?

- ¿Qué otras variables podrían estar impulsando la relación?
]

---
class: inverse, middle

# Haciendo Ajustes
&lt;img src="images/lognig.png" width="280" /&gt;

---
# Haciendo Ajustes

.pull-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-18-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[
Podemos producir una línea ajustada estimando una regresión de un resultado sobre un tratamiento: `$$Y_i = \beta_0 + \beta_1~D_i + \varepsilon_i$$`

`\(\beta\)` describe cómo cambia el resultado, *en promedio*, cuando cambia el tratamiento.

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Parámetro &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; (1) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Intercepto &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;font-weight: bold;"&gt; 1.22 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-weight: bold;"&gt; (0.18) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Tratamiento &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;font-weight: bold;"&gt; 0.56 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-weight: bold;"&gt; (0.08) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
.center[*Errores estandar en parentesis.*]
]

---
# Haciendo Ajustes

.pull-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-20-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[

Sin embargo, nos puede preocupar que una tercera variable `\(W_i\)` confunda nuestra estimación del efecto del tratamiento sobre el resultado.
]

---
# Haciendo Ajustes

.pull-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-21-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[

Si existen datos sobre la variable de control adicional, pueden añadirse al modelo de regresión: `$$Y_i = \beta_0 + \beta_1~D_i + \gamma_i~W_i + \varepsilon_i$$`
]

**P:** ¿Cómo "ajusta" MCO la inclusión de esa variable?

---
count: false
# Haciendo Ajustes

.pull-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-22-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[

Si existen datos sobre la variable de control adicional, pueden añadirse al modelo de regresión: `$$Y_i = \beta_0 + \beta_1~D_i + \gamma_i~W_i + \varepsilon_i$$`

**P:** ¿Cómo "ajusta" MCO la inclusión de esa variable?

- **Paso 1:** Averiguar qué diferencias en D se explican por W.
]



---
# Haciendo Ajustes

.pull-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-23-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[

Si existen datos sobre la variable de control adicional, pueden añadirse al modelo de regresión: `$$Y_i = \beta_0 + \beta_1~D_i + \gamma_i~W_i + \varepsilon_i$$`

**P:** ¿Cómo "ajusta" MCO la inclusión de esa variable?

- **Paso 2:** Remover las diferencias de D explicadas por W.
]

---
# Haciendo Ajustes

.pull-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-24-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[

Si existen datos sobre la variable de control adicional, pueden añadirse al modelo de regresión: `$$Y_i = \beta_0 + \beta_1~D_i + \gamma_i~W_i + \varepsilon_i$$`

**P:** ¿Cómo "ajusta" MCO la inclusión de esa variable?

- **Paso 3:** Miramos que diferencias de Y son explicadas por W
]



---
# Haciendo Ajustes

.pull-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-25-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[

Si existen datos sobre la variable de control adicional, pueden añadirse al modelo de regresión: `$$Y_i = \beta_0 + \beta_1~D_i + \gamma_i~W_i + \varepsilon_i$$`

**P:** ¿Cómo "ajusta" MCO la inclusión de esa variable?

- **Paso 4:** Removemos las diferencias de Y que son explicadas por W
]



---
# Haciendo Ajustes

.pull-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-26-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[

Si existen datos sobre la variable de control adicional, pueden añadirse al modelo de regresión: `$$Y_i = \beta_0 + \beta_1~D_i + \gamma_i~W_i + \varepsilon_i$$`

**P:** ¿Cómo "ajusta" MCO la inclusión de esa variable?

- **Paso 5:** Establecemos una regresión que se ajusta a los datos con que contamos

]

---
# Haciendo Ajustes

.pull-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-27-1.svg" style="display: block; margin: auto;" /&gt;
]
.pull-right[

Si la co-variable existe y se puede vincular, podemos entonces adherirla al modelo de regresión: `$$Y_i = \beta_0 + \beta_1~D_i + \gamma_i~W_i + \varepsilon_i$$`

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Parameter &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; (1) &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; (2) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Intercepto &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;"&gt; 1.22 &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;font-weight: bold;"&gt; 0.9 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;"&gt; (0.18) &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-weight: bold;"&gt; (0.1) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Tratamiento &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;"&gt; 0.56 &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;font-weight: bold;"&gt; -0.42 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;"&gt; (0.08) &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-weight: bold;"&gt; (0.07) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Covariable &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;font-weight: bold;"&gt; 3.91 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-weight: bold;"&gt; (0.2) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
.center[*Errores estandar en parentesis.*]
]

---
class: inverse, middle

# Sesgo de variables omitidas
&lt;img src="images/lognig.png" width="280" /&gt;


---
# Sesgo de variables omitidas

--

### **Ejemplo: Retornos de la educación**

.pull-left[
&lt;br&gt;
&lt;table&gt;
&lt;caption&gt;Resultado: Ganancia Semanal&lt;/caption&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Parámetro &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; 1 &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; 2 &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Intercepto &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;font-weight: bold;"&gt; 146.95 &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;"&gt; -128.89 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-weight: bold;"&gt; (77.72) &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;"&gt; (92.18) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Años de escolaridad &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;font-weight: bold;"&gt; 60.21 &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;"&gt; 42.06 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-weight: bold;"&gt; (5.70) &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;"&gt; (6.55) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Prueba IQ Score (Puntos) &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;font-weight: bold;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;"&gt; 5.14 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-weight: bold;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;"&gt; (0.96) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
.center[*Errores estándar en paréntesis.*]
]

.pull-right[

]

---
count: false
# Sesgo de variables omitidas

### **Ejemplo: Retornos de la educación**

.pull-left[
&lt;br&gt;
&lt;table&gt;
&lt;caption&gt;Resultado: Ganancia Semanal&lt;/caption&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Parámetro &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; 1 &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; 2 &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Intercepto &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;"&gt; 146.95 &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;font-weight: bold;"&gt; -128.89 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;"&gt; (77.72) &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-weight: bold;"&gt; (92.18) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Años de escolaridad &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;"&gt; 60.21 &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;font-weight: bold;"&gt; 42.06 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;"&gt; (5.70) &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-weight: bold;"&gt; (6.55) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;line-height: 110%;font-style: italic;color: black !important;"&gt; Prueba IQ Score (Puntos) &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;line-height: 110%;font-weight: bold;"&gt; 5.14 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-style: italic;color: black !important;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;color: #272822 !important;color: #c2bebe !important;line-height: 110%;font-weight: bold;"&gt; (0.96) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
.center[*Errores estándar en paréntesis.*]
]

--

.pull-right[
&lt;br&gt; &lt;br&gt;

.orange[Sesgo] por omitir el score de IQ 
&lt;br&gt; `\(\quad\)` .mono[=] .pink["Corto"] .mono[-] .purple["largo"]
&lt;br&gt; `\(\quad\)` .mono[=] .pink[60.21] .mono[-] .purple[42.06]
&lt;br&gt; `\(\quad\)` .mono[=] .orange[18.15]

La primera regresión atribuye erróneamente parte de la influencia de la inteligencia a la educación.
]

---
# Sesgo de variables omitidas

.more-left[
&lt;img src="Class01_files/figure-html/venn2-1.svg" style="display: block; margin: auto;" /&gt;
]

.less-right[

.hi-purple[Y] .mono[=] Resultado

.hi-green[D] .mono[=] Tratamiento

.hi-orange[W] .mono[=] Variable Omitida

Si .hi-orange[W] esta correlacionada con ambas .hi-green[D] y la variable .hi-purple[Y] .mono[--&gt;] el sesgo de variable omitida .mono[--&gt;] el método de regresión falla en aislar el efecto causal de la variable de tratamiento .hi-green[D] en .hi-purple[Y].
]

---
# Sesgo de variables omitidas

.more-left[
&lt;img src="Class01_files/figure-html/unnamed-chunk-31-1.svg" style="display: block; margin: auto;" /&gt;
]

.less-right[

.hi-purple[Y] .mono[=] Resultado

.hi-green[D] .mono[=] Tratamiento

.hi-orange[W] .mono[=] Variable Omitida

Si .hi-orange[W] esta correlacionada con ambas .hi-green[D] y la variable .hi-purple[Y] .mono[--&gt;] el sesgo de variable omitida .mono[--&gt;] el método de regresión falla en aislar el efecto causal de la variable de tratamiento .hi-green[D] en .hi-purple[Y].

]

---
class: inverse, middle

# Elementos adicionales e inferencia
&lt;img src="images/lognig.png" width="280" /&gt;

---
# Estimador

--

El modelo de regresión simple, obtendremos los estimadores `\(\hat{\beta}_0\)` y `\(\hat{\beta}_1\)` que minimiza la suma de los residuos al cuadrado (SSE), _p.e._,

--

`$$\min_{\hat{\beta}_0,\, \hat{\beta}_1} \text{SSE}$$`

--

Vamos a conocer que:

`$$\text{SSE} = \sum_i e_i^2$$`

--

La referencia es que los residuos `\(e_i\)` salen del modelo estimado o valor predicho de la .hi[dependiente] `\(\hat{y}\)` y de la variable resultado `\(y\)`.

--

$$
`\begin{aligned}
  e_i^2 &amp;= \left( y_i - \hat{y}_i \right)^2 = \left( y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i \right)^2 \\
  &amp;= y_i^2 - 2 y_i \hat{\beta}_0 - 2 y_i \hat{\beta}_1 x_i + \hat{\beta}_0^2 + 2 \hat{\beta}_0 \hat{\beta}_1 x_i + \hat{\beta}_1^2 x_i^2
\end{aligned}`
$$

--

**Recuerde:** Minimizar una función multivariada requiere 
1. La primera derivada (La condición de *1.super[er]-orden*) y, 
2. La condición de *2.super[do]-orden* o (concavidad).

---
# Estimador

--

Debemos **minimizar la SSE**

`$$\text{SSE} = \sum_{i=1}^{n} e_i^2 = \sum_{i=1}^n\left( y_i^2 - 2 y_i \hat{\beta}_0 - 2 y_i \hat{\beta}_1 x_i + \hat{\beta}_0^2 + 2 \hat{\beta}_0 \hat{\beta}_1 x_i + \hat{\beta}_1^2 x_i^2 \right)$$`

--

Dadas las condiciones de primer orden de .hi[minimización], realizamos la primera derivada de SSE con respecto a `\(\hat{\beta}_0\)` como de `\(\hat{\beta}_1\)`.

--

$$
`\begin{aligned}
  \dfrac{\partial \text{SSE}}{\partial \hat{\beta}_0} &amp;= \sum_i \left( 2 \hat{\beta}_0 + 2 \hat{\beta}_1 x_i - 2 y_i \right) = 2n \hat{\beta}_0 + 2 \hat{\beta}_1 \sum_i x_i - 2 \sum_i y_i \\
  &amp;= 2n \hat{\beta}_0 + 2n \hat{\beta}_1 \overline{x} - 2n \overline{y}
\end{aligned}`
$$

donde `\(\overline{x} = \frac{\sum x_i}{n}\)` y `\(\overline{y} = \frac{\sum y_i}{n}\)` son las medias muestrales de `\(x\)` e `\(y\)` (tamaño `\(n\)`).

---
# Estimador

--

Las condiciones de primer orden establecen que las derivadas son iguales a cero, por lo que:

--

`$$\dfrac{\partial \text{SSE}}{\partial \hat{\beta}_0} = 2n \hat{\beta}_0 + 2n \hat{\beta}_1 \overline{x} - 2n \overline{y} = 0$$`

--

`$$\hat{\beta}_0 = \overline{y} - \hat{\beta}_1 \overline{x}$$`

--

<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:red;overflow:visible;position:relative;"><path d="M256 8c137 0 248 111 248 248S393 504 256 504 8 393 8 256 119 8 256 8zM140 300h116v70.9c0 10.7 13 16.1 20.5 8.5l114.3-114.9c4.7-4.7 4.7-12.2 0-16.9l-114.3-115c-7.6-7.6-20.5-2.2-20.5 8.5V212H140c-6.6 0-12 5.4-12 12v64c0 6.6 5.4 12 12 12z"/></svg> Este .hi[estimador] viene a ser la diferencia entre los promedios de nuestras variables dependientes e independientes teniendo presente el efecto de `\(\hat{\beta}_1\)`.

--

Ahora solo nos falta por hallar `\(\hat{\beta}_1\)`.

---
# Estimador

--

Hay que tomar la derivada de SSE con respecto a `\(\hat{\beta}_1\)`

--

$$
`\begin{aligned}
  \dfrac{\partial \text{SSE}}{\partial \hat{\beta}_1} &amp;= \sum_i \left( 2 \hat{\beta}_0 x_i + 2 \hat{\beta}_1 x_i^2 - 2 y_i x_i \right) = 2 \hat{\beta}_0 \sum_i x_i + 2 \hat{\beta}_1 \sum_i x_i^2 - 2 \sum_i y_i x_i \\
  &amp;= 2n \hat{\beta}_0 \overline{x} + 2 \hat{\beta}_1 \sum_i x_i^2 - 2 \sum_i y_i x_i
\end{aligned}`
$$

todo igual a cero (condición de primer-orden, de nuevo)

--

`$$\dfrac{\partial \text{SSE}}{\partial \hat{\beta}_1} = 2n \hat{\beta}_0 \overline{x} + 2 \hat{\beta}_1 \sum_i x_i^2 - 2 \sum_i y_i x_i = 0$$`

--

y sustituimos `\(\hat{\beta}_0\)`, _p.e._, `\(\hat{\beta}_0 = \overline{y} - \hat{\beta}_1 \overline{x}\)`. Así,

--

$$
 2n \left(\overline{y} - \hat{\beta}_1 \overline{x}\right) \overline{x} + 2 \hat{\beta}_1 \sum_i x_i^2 - 2 \sum_i y_i x_i = 0
$$

---
# Estimador

--

Ya después de jugar con tanta álgebra:

--

$$2n \left(\overline{y} - \hat{\beta}_1 \overline{x}\right) \overline{x} + 2 \hat{\beta}_1 \sum_i x_i^2 - 2 \sum_i y_i x_i = 0 $$

--

a multiplicar

--

`$$2n \overline{y}\,\overline{x} - 2n \hat{\beta}_1 \overline{x}^2 + 2 \hat{\beta}_1 \sum_i x_i^2 - 2 \sum_i y_i x_i = 0$$`

--

`$$\implies 2 \hat{\beta}_1 \left( \sum_i x_i^2 - n \overline{x}^2 \right) = 2 \sum_i y_i x_i - 2n \overline{y}\,\overline{x}$$`

--

$$ \implies \hat{\beta}_1 = \dfrac{\sum_i y_i x_i - 2n \overline{y}\,\overline{x}}{\sum_i x_i^2 - n \overline{x}^2} = \dfrac{\sum_i (x_i - \overline{x})(y_i - \overline{y})}{\sum_i (x_i - \overline{x})^2} $$

---
# Estimador

--

Hecho!!

Ahora tenemos los estimadores MCO (encantadores) para la pendiente

--

`$$\hat{\beta}_1 = \dfrac{\sum_i (x_i - \overline{x})(y_i - \overline{y})}{\sum_i (x_i - \overline{x})^2}$$`
--

Para el intercepto o `\(\beta_{0}\)`

`$$\hat{\beta}_0 = \overline{y} - \hat{\beta}_1 \overline{x}$$`

--

Ahora **ya saben de dónde** sale formalmente la parte de *mínimos cuadrados* de MCO.

---
class: inverse, middle

# Función de esperanza condicional
&lt;img src="images/lognig.png" width="280" /&gt;

---
# Función de esperanza condicional

--

### La función de expectativa condicional

--

Decimos que `\(Y\)` es una variable aleatoria y `\(X=(X_1,X_2,...,X_k)\)` un vector de variables aleatorias explicativas. Si `\(E(|Y|)&lt;\infty\)` entonces hay una función `\(\mu:\mathbb{R}^k \to \mathbb{R}\)` tal que

--

`\begin{equation}
\tag{1}
E(Y|X_1,X_2,...,X_k)=\mu(X_1,X_2,...,X_k)
\end{equation}`

A esto lo llamamos la función de expectativa condicional y nos determina como cambia el valor medio de `\(Y\)` cuando cambian los elementos de `\(X\)`. 

Definimos el error de la expectativa condicional como la diferencia entre `\(Y\)` y el valor de la función de expectativa condicional evaluada en `\(X\)`

`\begin{equation}
\tag{2}
e=Y-\mu(X)
\end{equation}`

---
# Función de esperanza condicional

--

Luego por construcción

`\begin{equation}
\tag{2}
Y=\mu(X)+e
\end{equation}`

--

También, por construcción, tenemos que la expectativa condicional del error es cero

`\begin{align}
E(e|X)&amp;=E(Y-\mu(X)|X)\\
&amp;=E(Y|X)-E(\mu(X)|X)\\
&amp;=\mu(X)-\mu(X)\\
&amp;=0
\end{align}`

--

Y al usar la ley de expectativas iteradas, `\(E(E(Y|X))=E(Y)\)` tenemos que 

`\begin{equation}
E(e)=E(E(Y|X))=E(0)=0
\end{equation}`

--

Ahora, podemos especificar la función de expectativa condicional de la siguiente manera

`\begin{equation}
\mu(X)=\beta_0+\beta_1X_1+\beta_2X_2+...+\beta_kX_k
\end{equation}`

---
# Función de esperanza condicional

--

De donde podemos como cambios marginales en los regresores `\(X\)` impactan en la expectativa condicional de la variable de resultado `\(Y\)`. Si la variable `\(X_1\)` es continua, entonces

--

`\begin{equation}
\dfrac{\partial E(Y|X)}{\partial{X_1}}=\beta_1
\end{equation}`

Si la variable `\(X_1\)` es discreta y toma los valores `\(0\)` y `\(1\)`, entonces tenemos que

--

`\begin{equation}
E(Y|X_1=1)-E(Y|X_1=0)=\beta_1
\end{equation}`

En otras palabras, los parámetros recogen el cambio en la expectativa condicional de `\(Y\)` atribuible a `\(X\)`, dado que todo lo demás está constante. Todo lo demás significa todas las demás variables explícitamente incorporadas en el modelo. Ahora, si usamos la forma lineal en `\((2)\)` tenemos que

--

`\begin{equation}
Y=\beta_0+\beta_1X_1+\beta_2X_2+...+\beta_kX_k+u
\end{equation}`

De donde podemos concluir que los parámetros capturan el cambio en el valor actual de `\(Y\)` atribuible al cambio en la independiente, solo si el error `\(e\)` no está afectado por el regresor que se modifica. Esto nos lleva a la discusión sobre efectos causales

---


&lt;img src="Class01_files/figure-html/fig_cef_dist-1.svg" style="display: block; margin: auto;" /&gt;
---
&lt;img src="Class01_files/figure-html/fig_cef-1.svg" style="display: block; margin: auto;" /&gt;
---
&lt;img src="Class01_files/figure-html/fig_cef_only-1.svg" style="display: block; margin: auto;" /&gt;
---
class: inverse
# Bibliografía

<svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M448 360V24c0-13.3-10.7-24-24-24H96C43 0 0 43 0 96v320c0 53 43 96 96 96h328c13.3 0 24-10.7 24-24v-16c0-7.5-3.5-14.3-8.9-18.7-4.2-15.4-4.2-59.3 0-74.7 5.4-4.3 8.9-11.1 8.9-18.6zM128 134c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm0 64c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm253.4 250H96c-17.7 0-32-14.3-32-32 0-17.6 14.4-32 32-32h285.4c-1.9 17.1-1.9 46.9 0 64z"/></svg> Angrist, J. D., &amp; Pischke, J. S. (2009). *Mostly harmless econometrics: An empiricist's companion*. Princeton university press.

<svg aria-hidden="true" role="img" viewBox="0 0 384 512" style="height:1em;width:0.75em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M384 121.941V128H256V0h6.059c6.365 0 12.47 2.529 16.971 7.029l97.941 97.941A24.005 24.005 0 0 1 384 121.941zM248 160c-13.2 0-24-10.8-24-24V0H24C10.745 0 0 10.745 0 24v464c0 13.255 10.745 24 24 24h336c13.255 0 24-10.745 24-24V160H248zM123.206 400.505a5.4 5.4 0 0 1-7.633.246l-64.866-60.812a5.4 5.4 0 0 1 0-7.879l64.866-60.812a5.4 5.4 0 0 1 7.633.246l19.579 20.885a5.4 5.4 0 0 1-.372 7.747L101.65 336l40.763 35.874a5.4 5.4 0 0 1 .372 7.747l-19.579 20.884zm51.295 50.479l-27.453-7.97a5.402 5.402 0 0 1-3.681-6.692l61.44-211.626a5.402 5.402 0 0 1 6.692-3.681l27.452 7.97a5.4 5.4 0 0 1 3.68 6.692l-61.44 211.626a5.397 5.397 0 0 1-6.69 3.681zm160.792-111.045l-64.866 60.812a5.4 5.4 0 0 1-7.633-.246l-19.58-20.885a5.4 5.4 0 0 1 .372-7.747L284.35 336l-40.763-35.874a5.4 5.4 0 0 1-.372-7.747l19.58-20.885a5.4 5.4 0 0 1 7.633-.246l64.866 60.812a5.4 5.4 0 0 1-.001 7.879z"/></svg> Rubin, E. (2021) *Econometrics Lectures class*.

<svg aria-hidden="true" role="img" viewBox="0 0 384 512" style="height:1em;width:0.75em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M384 121.941V128H256V0h6.059c6.365 0 12.47 2.529 16.971 7.029l97.941 97.941A24.005 24.005 0 0 1 384 121.941zM248 160c-13.2 0-24-10.8-24-24V0H24C10.745 0 0 10.745 0 24v464c0 13.255 10.745 24 24 24h336c13.255 0 24-10.745 24-24V160H248zM123.206 400.505a5.4 5.4 0 0 1-7.633.246l-64.866-60.812a5.4 5.4 0 0 1 0-7.879l64.866-60.812a5.4 5.4 0 0 1 7.633.246l19.579 20.885a5.4 5.4 0 0 1-.372 7.747L101.65 336l40.763 35.874a5.4 5.4 0 0 1 .372 7.747l-19.579 20.884zm51.295 50.479l-27.453-7.97a5.402 5.402 0 0 1-3.681-6.692l61.44-211.626a5.402 5.402 0 0 1 6.692-3.681l27.452 7.97a5.4 5.4 0 0 1 3.68 6.692l-61.44 211.626a5.397 5.397 0 0 1-6.69 3.681zm160.792-111.045l-64.866 60.812a5.4 5.4 0 0 1-7.633-.246l-19.58-20.885a5.4 5.4 0 0 1 .372-7.747L284.35 336l-40.763-35.874a5.4 5.4 0 0 1-.372-7.747l19.58-20.885a5.4 5.4 0 0 1 7.633-.246l64.866 60.812a5.4 5.4 0 0 1-.001 7.879z"/></svg> Raze, K. (2022) *Labor Economics Lectures class*.

<svg aria-hidden="true" role="img" viewBox="0 0 576 512" style="height:1em;width:1.12em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"/></svg> Angrist, J. (2022) *Mastering Econometrics* [Con Acceso abril 2022](https://mru.org/mastering-econometrics-joshua-angrist).

<svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M448 360V24c0-13.3-10.7-24-24-24H96C43 0 0 43 0 96v320c0 53 43 96 96 96h328c13.3 0 24-10.7 24-24v-16c0-7.5-3.5-14.3-8.9-18.7-4.2-15.4-4.2-59.3 0-74.7 5.4-4.3 8.9-11.1 8.9-18.6zM128 134c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm0 64c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm253.4 250H96c-17.7 0-32-14.3-32-32 0-17.6 14.4-32 32-32h285.4c-1.9 17.1-1.9 46.9 0 64z"/></svg> Wooldridge, J. M. (2015). *Introductory econometrics: A modern approach*. Cengage learning.


---
name: adios
class: middle, inverse

.pull-left[
# **¡Gracias!**
&lt;br/&gt;
## Econometría I

### Seguimos aprendiendo
]

.pull-right[
.right[
&lt;img style="border-radius: 50%;"
src="https://avatars.githubusercontent.com/u/39503983?v=4"
width="150px" /&gt;

[<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg> Syllabus/ Curso](https://ignaciomsarmiento.github.io/teaching/UniNorte/Syllabus__Ciencia_de_Datos_TDE.pdf)&lt;br/&gt;
[<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> @keynes37](https://twitter.com/keynes37)&lt;br/&gt;
[<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg> cayanes@uninorte.edu.co](mailto:cayanes@uninorte.edu.co)
]
]

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>

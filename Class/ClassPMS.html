<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Econometría</title>
    <meta charset="utf-8" />
    <meta name="author" content="Carlos A. Yanes Guerra" />
    <meta name="date" content="2024-01-01" />
    <script src="libs/header-attrs-2.26/header-attrs.js"></script>
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <script src="libs/xaringanExtra_fit-screen-0.2.6/fit-screen.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="my-css.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

name: xaringan-title
class: inverse, left, bottom
background-image: url(images/beach1.jpg)
background-size: cover





$$
`\begin{align}
  \def\ci{\perp\mkern-10mu\perp}
\end{align}`
$$
# **Econometría**
----

## **&lt;br/&gt; Matching**

### Carlos A. Yanes Guerra
### 2024

---
class: inverse, middle

# Resumen
&lt;img src="images/lognig.png" width="280" /&gt;

---
# Resumen

--

### Empecemos

--

¿Recuerda el .hi[supuesto de independencia condicional].super[.pink[†]] en un contexto—_es decir_, el tratamiento es tan bueno como poseer un aleatorio condicional en un conjunto conocido de co-variables?

.footnote[.pink[†] También conocido como "selección en observables"]

--

Los .hi[estimadores de emparejamiento] toman la palabra ahora.

--

Si realmente creemos que `\(\left(\text{Y}_{1i},\, \text{Y}_{0i} \right)\ci \text{D}_{i}|\text{X}_{i}\)`, entonces simplemente podemos calcular un montón de efectos del tratamiento condicionales en `\(\text{X}_{i}\)`, _es decir_,
$$
`\begin{align}
  \tau(x) = \mathop{E}\left[ \text{Y}_{1i} - \text{Y}_{0i} \mid \text{X}_{i} = x \right]
\end{align}`
$$

--

.note[La idea:] Estimar un .hi[efecto] del tratamiento solo usando observaciones con valores (¿casi?) idénticos de `\(\text{X}_{i}\)`.
--
La .pink[condición de independencia condicional] (CIA) nos proporciona causalidad dentro de estos grupos.

---
# Resumen

--

## Objetivo

--

Volvamos por un momento al .b[problema fundamental de la inferencia causal].

1. Queremos/necesitamos saber `\(\tau_i = \text{Y}_{1i} - \text{Y}_{0i}\)`.
2. No podemos observar simultáneamente *tanto* `\(\text{Y}_{1i}\)` *como* `\(\text{Y}_{0i}\)`.

--

La mayoría (¿todas?) de las .ul[estrategias empíricas] se reducen a estimar `\(\text{Y}_{0i}\)` para los individuos tratados—el contrafactual no observable para el grupo de tratamiento.

--

El .hi-purple[emparejamiento] no se hace diferente.

Emparejamos observaciones .hi[no tratadas] con observaciones tratadas utilizando `\(\text{X}_{i}\)`, _es decir_, calculamos un `\(\widehat{\text{Y}_{0i}}\)` para cada `\(\text{Y}_{1i}\)`, basado en individuos no tratados que buscamos "emparejar".

---
# Resumen

--

&gt; La metodología PSM es particularmente útil en estudios observacionales donde se quiere estimar el efecto causal de una intervención (tratamiento) sobre un resultado de interés, sin la aleatorización típica de los experimentos controlados. Es decir, cuando no podemos asignar aleatoriamente a los individuos a un grupo de tratamiento y otro de control.

--

En sintesis es mejor **hacerlo** cuando:

--

<svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:red;overflow:visible;position:relative;"><path d="M224 0c-17.7 0-32 14.3-32 32V49.9C119.5 61.4 64 124.2 64 200v33.4c0 45.4-15.5 89.5-43.8 124.9L5.3 377c-5.8 7.2-6.9 17.1-2.9 25.4S14.8 416 24 416H424c9.2 0 17.6-5.3 21.6-13.6s2.9-18.2-2.9-25.4l-14.9-18.6C399.5 322.9 384 278.8 384 233.4V200c0-75.8-55.5-138.6-128-150.1V32c0-17.7-14.3-32-32-32zm0 96h8c57.4 0 104 46.6 104 104v33.4c0 47.9 13.9 94.6 39.7 134.6H72.3C98.1 328 112 281.3 112 233.4V200c0-57.4 46.6-104 104-104h8zm64 352H224 160c0 17 6.7 33.3 18.7 45.3s28.3 18.7 45.3 18.7s33.3-6.7 45.3-18.7s18.7-28.3 18.7-45.3z"/></svg> Debe identificar claramente a los individuos que recibieron el tratamiento (grupo de tratamiento) y aquellos que no lo recibieron (grupo de control).

--

<svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:red;overflow:visible;position:relative;"><path d="M224 0c-17.7 0-32 14.3-32 32V49.9C119.5 61.4 64 124.2 64 200v33.4c0 45.4-15.5 89.5-43.8 124.9L5.3 377c-5.8 7.2-6.9 17.1-2.9 25.4S14.8 416 24 416H424c9.2 0 17.6-5.3 21.6-13.6s2.9-18.2-2.9-25.4l-14.9-18.6C399.5 322.9 384 278.8 384 233.4V200c0-75.8-55.5-138.6-128-150.1V32c0-17.7-14.3-32-32-32zm0 96h8c57.4 0 104 46.6 104 104v33.4c0 47.9 13.9 94.6 39.7 134.6H72.3C98.1 328 112 281.3 112 233.4V200c0-57.4 46.6-104 104-104h8zm64 352H224 160c0 17 6.7 33.3 18.7 45.3s28.3 18.7 45.3 18.7s33.3-6.7 45.3-18.7s18.7-28.3 18.7-45.3z"/></svg>  Definir claramente la variable que quiere medir para evaluar el efecto del .pink[tratamiento] (por ejemplo, ingresos, productividad, estado de salud).

--

<svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:red;overflow:visible;position:relative;"><path d="M224 0c-17.7 0-32 14.3-32 32V49.9C119.5 61.4 64 124.2 64 200v33.4c0 45.4-15.5 89.5-43.8 124.9L5.3 377c-5.8 7.2-6.9 17.1-2.9 25.4S14.8 416 24 416H424c9.2 0 17.6-5.3 21.6-13.6s2.9-18.2-2.9-25.4l-14.9-18.6C399.5 322.9 384 278.8 384 233.4V200c0-75.8-55.5-138.6-128-150.1V32c0-17.7-14.3-32-32-32zm0 96h8c57.4 0 104 46.6 104 104v33.4c0 47.9 13.9 94.6 39.7 134.6H72.3C98.1 328 112 281.3 112 233.4V200c0-57.4 46.6-104 104-104h8zm64 352H224 160c0 17 6.7 33.3 18.7 45.3s28.3 18.7 45.3 18.7s33.3-6.7 45.3-18.7s18.7-28.3 18.7-45.3z"/></svg> Identificar todas las variables observables que podrían influir tanto en la decisión de recibir el tratamiento como en el resultado de interés. Estas covariables deben ser medidas antes de que se asigne el tratamiento.

--

<svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:red;overflow:visible;position:relative;"><path d="M224 0c-17.7 0-32 14.3-32 32V49.9C119.5 61.4 64 124.2 64 200v33.4c0 45.4-15.5 89.5-43.8 124.9L5.3 377c-5.8 7.2-6.9 17.1-2.9 25.4S14.8 416 24 416H424c9.2 0 17.6-5.3 21.6-13.6s2.9-18.2-2.9-25.4l-14.9-18.6C399.5 322.9 384 278.8 384 233.4V200c0-75.8-55.5-138.6-128-150.1V32c0-17.7-14.3-32-32-32zm0 96h8c57.4 0 104 46.6 104 104v33.4c0 47.9 13.9 94.6 39.7 134.6H72.3C98.1 328 112 281.3 112 233.4V200c0-57.4 46.6-104 104-104h8zm64 352H224 160c0 17 6.7 33.3 18.7 45.3s28.3 18.7 45.3 18.7s33.3-6.7 45.3-18.7s18.7-28.3 18.7-45.3z"/></svg> El modelo estadístico de implementación estima la probabilidad de que un individuo reciba el tratamiento, basado en las covariables observadas.


---
class: inverse, middle

# Emparejamiento
&lt;img src="images/lognig.png" width="280" /&gt;

---
layout:true
# Emparejamiento (Matching)


---
## Más formalmente

--

Queremos construir un contrafactual para cada individuo con `\(\text{D}_{i}=1\)`.

--

.note[CIA:] El contrafactual para `\(i\)` solo debe usar individuos que coincidan con `\(\text{X}_{i}\)`.

--

Supongamos que hay `\(N_T\)` individuos tratados y `\(N_C\)` individuos de control. Queremos
- `\(N_T\)` conjuntos de pesos (ponderables)
- con `\(N_C\)` pesos en cada conjunto
--
: `\(w_i(j)\, \left( i = 1,\,\ldots,\, N_T;\, j=1,\,\ldots,\, N_C \right)\)`

--

Supongamos que `\(\sum_j w_i(j) = 1\)`. Nuestra estimación para el contrafactual del tratado `\(i\)` es
$$
`\begin{align}
  \widehat{\text{Y}_{0i}} = \sum_{j\in \left( D=0 \right)} w_i(j) \text{Y}_{j}
\end{align}`
$$
---

--

## Más formalmente

Si nuestra estimación del contrafactual para el individuo tratado `\(i\)` es
$$
`\begin{align}
  \widehat{\text{Y}_{0i}} = \sum_j w_i(j) \text{Y}_{j}
\end{align}`
$$
entonces nuestro estimado del efecto del tratamiento (para el individuo `\(i\)`) será
$$
`\begin{align}
  \hat{\tau}_i = \text{Y}_{1i} - \widehat{\text{Y}_{0i}} = \text{Y}_{1i} - \sum_j w_i(j) \text{Y}_{j}
\end{align}`
$$

--

<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:red;overflow:visible;position:relative;"><path d="M256 512A256 256 0 1 0 256 0a256 256 0 1 0 0 512zM216 336h24V272H216c-13.3 0-24-10.7-24-24s10.7-24 24-24h48c13.3 0 24 10.7 24 24v88h8c13.3 0 24 10.7 24 24s-10.7 24-24 24H216c-13.3 0-24-10.7-24-24s10.7-24 24-24zm40-208a32 32 0 1 1 0 64 32 32 0 1 1 0-64z"/></svg> Un estimador genérico de emparejamiento para el .pink[efecto del tratamiento en los tratados] vendria a ser
$$
`\begin{align}
  \hat{\tau}_M = \dfrac{1}{N_T} \sum_{i \in \left( \text{D}=1 \right)} \left( \text{Y}_{1i} - \widehat{\text{Y}_{0i}} \right) = \dfrac{1}{N_T} \sum_{i \in \left( \text{D}=1 \right)} \left( \text{Y}_{1i} - \sum_{j\in \left( D=0 \right)} w_i(j) \text{Y}_{j} \right)
\end{align}`
$$
---

--

## Clave y elemental!!

Así que todo lo que necesitamos son esos pesos y hemos terminado..super[.pink[†]]

.footnote[.pink[†] Además de un contexto interesante y relevante para la política que se evaluac teniendo presente siempre el supuesto de independencia condicional válida, ademas de los datos.
]

--

.hi[P] ¿Dónde se encuentran esos pesos/ponderadores tan útiles?

--

.hi-blue[R] Tienes opciones, pero debes elegir con cuidado/responsabilidad.

*Ejemplo*, si `\(w_i(j) = \frac{1}{N_C}\)` para todos `\((i,j)\)`, entonces volvemos a una diferencia de medias.
&lt;br&gt; Este peso no respeta nuestro supuesto de independencia condicional.

--

.note[El plan] Elegir pesos `\(w_i(j)\)` que indiquen .hi-slate[*qué tan cerca*] está `\(\text{X}_{j}\)` de `\(\text{X}_{i}\)`.
---

--

## Proximidad/cercanía

Nuestros pesos `\(w_i(j)\)` deben ser una medida de .hi-slate[*qué tan cerca*] está `\(\text{X}_{j}\)` de `\(\text{X}_{i}\)`.

--

Si `\(\text{X}\)` es una variable .hi-pink[discreta], entonces podemos considerar la igualdad, _es decir_, `\(w_i(j) = \mathbb{I}(\text{X}_{i} = \text{X}_{j})\)`, escalando según sea necesario para obtener `\(\sum_j w_i(j) = 1\)`.

---

--

## Proximidad/cercanía

Nuestros pesos `\(w_i(j)\)` deben ser una medida de .hi-slate[*qué tan cerca*] está `\(\text{X}_{j}\)` de `\(\text{X}_{i}\)`.

Si `\(\text{X}\)` es una variable .hi-purple[continua], entonces necesitamos .it[proximidad] en lugar de .it[igualdad].

--

.purple[El emparejamiento del vecino más cercano] elige la única observación de control más cercana utilizando la distancia euclidiana entre `\(\text{X}_{i}\)` y `\(\text{X}_{j}\)`, _es decir_,

$$
`\begin{align}
  \text{d}_{i,j} = \left( \text{X}_{i} - \text{X}_{j} \right)'\left(\text{X}_{i} - \text{X}_{j}\right)
\end{align}`
$$

--

- `\(\hat{\tau}_i = \text{Y}_{1i} - \text{Y}_{0j}^i\)`, donde `\(\text{Y}_{0j}^i\)` es el vecino más cercano de `\(i\)` en el grupo de control.
- .hi-slate[Estimador:] `\(\hat{\tau}_M = \frac{1}{N_T} \sum_i \hat{\tau}_i\)`
- Produce estimaciones causales si la CIA es válida *y* tenemos suficiente superposición.
- Sufre de elecciones arbitrarias de unidades.

---

--

## Proximidad/cercanía

Nuestros pesos `\(w_i(j)\)` deben ser una medida de .hi-slate[*qué tan cerca*] está `\(\text{X}_{j}\)` de `\(\text{X}_{i}\)`.

Si `\(\text{X}\)` es .hi-purple[continua], entonces necesitamos .it[proximidad] en lugar de .it[igualdad].

.purple[El emparejamiento del vecino más cercano con distancia de Mahalanobis] elige el control más cercano utilizando la distancia .purple[Mahalanobis] entre `\(\text{X}_{i}\)` y `\(\text{X}_{j}\)`, _es decir_,

$$
`\begin{align}
  \text{d}_{i,j} = \left( \text{X}_{i} - \text{X}_{j} \right)' \Sigma_{X}^{-1} \left(\text{X}_{i} - \text{X}_{j}\right)
\end{align}`
$$
donde `\(\Sigma_{X}^{-1}\)` es la matriz de covarianza de `\(\text{X}\)`.

--

- .hi-slate[Estimador:] `\(\hat{\tau}_M = \frac{1}{N_T} \sum_i \hat{\tau}_i\)` donde `\(\left(\hat{\tau}_i = \text{Y}_{1i} - \text{Y}_{0j}^i\right)\)`
- Produce estimaciones causales si la CIA es válida *y* tenemos suficiente superposición.
- No sufre de elecciones arbitrarias de unidades.

---

--

## Proximidad/cercanía

Nuestros pesos `\(w_i(j)\)` deberían ser una medida de **qué tan cerca** está `\(\text{X}_{j}\)` de `\(\text{X}_{i}\)`.

Si `\((\text{X})\)` es **continua**, entonces necesitamos **proximidad** en lugar de **igualdad**.

**El emparejamiento del vecino más cercano con distancia de Mahalanobis** elige el control más cercano utilizando la distancia de Mahalanobis entre `\(\text{X}_{i}\)` y `\(\text{X}_{j}\)`, es decir,

donde `\(\Sigma_{X}^{-1}\)` es la matriz de covarianza de `\(\text{X}\)`.

--

- **Estimador:** `\(\hat{\tau}_M = \frac{1}{N_T} \sum_i \hat{\tau}_i\)` donde `\(\left(\hat{\tau}_i = \text{Y}_{1i} - \text{Y}_{0j}^i\right)\)`
- Produce estimaciones causales si la CIA es válida *y* tenemos suficiente overlaping.
- No sufre de elecciones arbitrarias de unidades.

---

--

## ¿Más vecinos?

--

¿Por qué limitarnos a una **única** "mejor" coincidencia?

--

Si vamos a permitir que una función/algoritmo elija la coincidencia *más cercana*, ¿no podríamos también permitir que la función/algoritmo elija *cuántas* coincidencias?

--

Además, si `\(N_C \gg N_T\)`, estamos desperdiciando *mucha* información.

--

Podríamos utilizar esta información y ser aún más eficientes.

---

--

## ¡Más vecinos!

**El emparejamiento por Kernel** da un peso positivo a todas las observaciones de control dentro de un **ancho de banda** `\(h\)`, con mayor peso para las coincidencias más cercanas determinado por alguna **función de kernel** `\(K(\cdot)\)`,

$$
`\begin{align}
  w_i(j) = \dfrac{K\!\!\left( \dfrac{\text{X}_{j} - \text{X}_{i}}{h} \right)}{\sum_{j\in(D=0)} K\!\!\left(\dfrac{\text{X}_{j} - \text{X}_{i}}{h} \right)}
\end{align}`
$$

--

**Ejemplo:** El *kernel de Epanechnikov* se define como

$$
`\begin{align}
  K(z) = \dfrac{3}{4} \left( 1 - z^2 \right) \times \mathbb{I}\!\left( |z| &lt; 1 \right)
\end{align}`
$$
---
layout: false
class: clear

.hi-orange[El kernel de Epanechnikov] `\(K(z) = \frac{3}{4} \left( 1 - z^2 \right) \times \mathbb{I}\!\left( |z| &lt; 1 \right)\)`

&lt;img src="ClassPMS_files/figure-html/epanechnikov-1.svg" style="display: block; margin: auto;" /&gt;
---
layout: false
class: clear

&lt;img src="ClassPMS_files/figure-html/ex_epanechnikov-1.svg" style="display: block; margin: auto;" /&gt;

---
class: clear
count: false

&lt;img src="ClassPMS_files/figure-html/ex_epa_point-1.svg" style="display: block; margin: auto;" /&gt;

--

&lt;img src="ClassPMS_files/figure-html/ex_weights-1.svg" style="display: block; margin: auto;" /&gt;
---
layout: false
class: clear

.hi-orange[The Epanechnikov kernel] `\(K(z) = \frac{3}{4} \left( 1 - z^2 \right) \times \mathbb{I}\!\left( |z| &lt; 1 \right)\)`

&lt;img src="ClassPMS_files/figure-html/epanechnikov2-1.svg" style="display: block; margin: auto;" /&gt;
---
layout: false
class: clear

.hi-orange[El Triangulo kernel] `\(K(z) = \left( 1 - |z| \right) \times \mathbb{I}\!\left( |z| &lt; 1 \right)\)`

&lt;img src="ClassPMS_files/figure-html/triangle-1.svg" style="display: block; margin: auto;" /&gt;
---
layout: false
class: clear

.hi-orange[El kernel Uniforme] `\(K(z) = \frac{1}{2} \times \mathbb{I}\!\left( |z| &lt; 1 \right)\)`

&lt;img src="ClassPMS_files/figure-html/uniform-1.svg" style="display: block; margin: auto;" /&gt;
---
layout: false
class: clear

.hi-orange[El kernel Gausiano] `\(K(z) = \left( 2\pi \right)^{-1/2}  \exp\left(-z^2/2 \right)\)`

&lt;img src="ClassPMS_files/figure-html/gaussian-1.svg" style="display: block; margin: auto;" /&gt;

---
layout: false
class: inverse, middle

# El método de Propensity score
&lt;img src="images/lognig.png" width="280" /&gt;

---
layout: true

# Propensity Score Matching 

---

--

## Vamos a dar mas claridad

--

Las funciones .hi-orange[kernel] son útiles para más que solo el .hi[emparejamiento].

Lo más común es que las veas/utilices suavizando densidades, proporcionando .hi-blue[un promedio] suave de una ventana móvil.

--

_Ej._, la función de suavizado y graficado de densidad en `.mono[R]` como (`ggplot2`) `geom_density()`.

`geom_density()` por defecto usa `kernel = "gaussian"`, pero puedes especificar muchas otras funciones kernel (incluyendo `"epanechnikov"`).

--

También puedes cambiar el argumento `bandwidth`. El valor predeterminado es una función de selección de ancho de banda llamada `bw.nrd0()`.

---

--

## Añadiendo vecinos

--

A medida que agregamos más vecinos—ya sea pasando de `\(1\)` a `\(n&gt;1\)` o aumentando nuestro ancho de banda—potencialmente incrementamos la .hi[eficiencia] de nuestro estimador.

--

Necesitamos .hi[tener cuidado de no agregar *demasiados* controles] para cada tratado `\(i\)`.

--

La CIA requiere que realmente estemos condicionando en las observables; no nos permite tomar un promedio simple de todas las observaciones de control.

---

--

## La maldición de la dimensionalidad

--

Resulta que la .ul[selección] de kernel y ancho de banda no son nuestros "peores" enemigos.

--

A medida que la dimensión de `\(\text{X}\)` se expande (emparejando en más variables), se vuelve .hi[cada vez más difícil encontrar un control cercano y adecuado] para cada unidad tratada.

--

Necesitamos una forma de reducir la dimensionalidad de `\(\text{X}\)`.

---
layout: false
class: inverse, middle

# PSM su uso
&lt;img src="images/lognig.png" width="280" /&gt;

---
layout: true
# PSM

---

--

## Miremos como hacerlo

--

Comencemos con dos supuestos, uno antiguo y uno nuevo.

1. .hi-purple[Independencia condicional:] `\(\left( \text{Y}_{0i},\, \text{Y}_{1i} \right) \ci \text{D}_{i}|\text{X}_{i}\)`

--

2. .hi-purple[Overlap:] `\(0 &lt; \mathop{\text{Pr}}\left(\text{D}_{i} = 1 \mid \text{X}_{i}\right) &lt; 1\)`

--

Podemos estimar un efecto promedio del tratamiento condicionando en `\(\text{X}_{i}\)`.

--

Sin embargo, la superposición puede fallar si las dimensiones de `\(X\)` son grandes y `\(N\)` es finito.

--

.hi[Los puntajes de la propensión] a ser elegido como .hi[tratado] para hacerlo *pasar* como .hi-purple[control] proponen una solución a este problema.

---

--

## La magia

--

Resulta que si `\(\left( \text{Y}_{0i},\,\text{Y}_{1i} \right) \ci \text{D}_{i}|\text{X}_{i},\,\)` entonces realmente solo necesitamos emparejar/condicionar en `\(p(\text{X}_{i}) = \mathop{E}\left[ \text{D}_{i} | \text{X}_{i} \right]\)`.

--

`\(p(\text{X}_{i})\)` es el .attn[puntaje de la propensión],
--
la probabilidad de tratamiento dado `\(\text{X}_{i}.\)`

--

.attn[Teorema del puntaje de propensión] Si `\(\left( \text{Y}_{0i},\,\text{Y}_{1i} \right) \ci \text{D}_{i}|\text{X}_{i},\,\)` entonces `\(\left( \text{Y}_{0i},\,\text{Y}_{1i} \right) \ci \text{D}_{i}|p(\text{X}_{i}).\)`

--

Este teorema extiende nuestra CIA a un puntaje unidimensional, evitando la **maldición de la dimensionalidad**.

---
layout: true
# Prueba en estimación

.note[Teorema] si `\(\left( \text{Y}_{0i},\,\text{Y}_{1i} \right) \ci \text{D}_{i}|\text{X}_{i},\,\)` luego `\(\left( \text{Y}_{0i},\,\text{Y}_{1i} \right) \ci \text{D}_{i}|p(\text{X}_{i}).\)`

## Prueba

---


--

Para probar esto, se requiere que `\(\mathop{\text{Pr}}\left(\text{D}_{i}=1 \mid \text{Y}_{0i},\, \text{Y}_{1i},\, p(\text{X}_{i})\right) = p(\text{X}_{i})\)`, _i.e._, `\(\text{D}_{i}\)` es independiente de `\(\left( \text{Y}_{0i},\, \text{Y}_{1i} \right)\)` despues de condicionar `\(p(\text{X}_{i})\)`.

---
count: false

`\(\mathop{\text{Pr}}\!\bigg[\text{D}_{i}=1 \bigg| \text{Y}_{0i},\, \text{Y}_{1i},\, p(\text{X}_{i})\bigg]\)`

--
.pad-left[
`\(=\mathop{E}\!\bigg[\text{D}_i \bigg| \text{Y}_{0i},\, \text{Y}_{1i},\, p(\text{X}_{i})\bigg]\)`
]

--
.pad-left[
`\(=\mathop{E}\!\bigg[ \mathop{E}\!\bigg(\text{D}_i \bigg| \text{Y}_{0i},\, \text{Y}_{1i},\, p(\text{X}_{i}),\, \text{X}_{i} \bigg) \bigg| \text{Y}_{0i},\, \text{Y}_{1i},\, p(\text{X}_{i})\bigg]\)`
]

--
.pad-left[
`\(=\mathop{E}\!\bigg[ \mathop{E}\!\bigg(\text{D}_i \bigg| \text{Y}_{0i},\, \text{Y}_{1i},\, \text{X}_{i} \bigg) \bigg| \text{Y}_{0i},\, \text{Y}_{1i},\, p(\text{X}_{i})\bigg]\)`
]
---

`\(\mathop{\text{Pr}}\!\bigg[\text{D}_{i}=1 \bigg| \text{Y}_{0i},\, \text{Y}_{1i},\, p(\text{X}_{i})\bigg]= \cdots =\mathop{E}\!\bigg[ \mathop{E}\!\bigg(\text{D}_i \bigg| \text{Y}_{0i},\, \text{Y}_{1i},\, \text{X}_{i} \bigg) \bigg| \text{Y}_{0i},\, \text{Y}_{1i},\, p(\text{X}_{i})\bigg]\)`

--
.pad-left[
`\(=\mathop{E}\!\bigg[ \mathop{E}\!\bigg(\text{D}_i \bigg| \text{X}_{i} \bigg) \bigg| \text{Y}_{0i},\, \text{Y}_{1i},\, p(\text{X}_{i})\bigg]\)`
]

--
.pad-left[
`\(=\mathop{E}\!\bigg[ p(\text{X}_{i}) \bigg| \text{Y}_{0i},\, \text{Y}_{1i},\, p(\text{X}_{i})\bigg]\)`
]

--
.pad-left[
`\(=p(\text{X}_{i})\)`
]

--

∴ `\(\left( \text{Y}_{0i},\,\text{Y}_{1i} \right) \ci \text{D}_{i}|\text{X}_{i} \implies \left( \text{Y}_{0i},\,\text{Y}_{1i} \right) \ci \text{D}_{i}|p(\text{X}_{i})\)` .orange[✔]

---
layout:false
class: inverse, middle

# Estimación PSM final
&lt;img src="images/lognig.png" width="280" /&gt;

---
layout: true
# PSM

---

--

## Intuición

--

.hi[P] ¿Qué está pasando aquí?

--

`\(\text{X}_{i}\)` lleva mucha más información que `\(p(\text{X}_{i})\)`, entonces, ¿cómo podemos seguir obteniendo independencia condicional del tratamiento solo condicionando en `\(p(\text{X}_{i})\)`?

--

.hi[R].sub[.pink[1]] La independencia condicional del tratamiento no se trata de extraer toda la información posible de `\(\text{X}_{i}\)`. En realidad, solo nos importa crear una situación en la que `\(\text{D}_{i}|\)` algo sea independiente de `\(\left( \text{Y}_{0i},\,\text{Y}_{1i} \right)\)`.

--

.hi[R].sub[.pink[2]] Volviendo a nuestra principal preocupación: .hi-orange[sesgo de selección]. Las personas se seleccionan en el tratamiento. Si `\(\text{X}\)` dice que dos personas tenían la misma probabilidad de ser tratadas, y si `\(\text{X}_{i}\)` explica toda la selección (CIA), entonces no puede haber selección entre estas dos personas.

---

--

## Estimación

--

Entonces, ¿de dónde vienen los .hi-blue[puntajes de propensión]?

--

Los estimamos, y hay muchas formas de hacerlo.

--

1. Especificación logit flexible (_es decir_, interacciones)
2. Regresión kernel (¿recuerdas las funciones kernel?)
3. Muchas otras: aprendizaje automático, estimador de series-logit, *etc.*

--

.hi[P] ¿Podemos usar simplemente MPL(OLS) (modelo de probabilidad lineal)?

--

.qa[R] En cierto modo. Piense en FWL (teorema Frisch-Waugh-Lovell. Esta ruta va a ser la misma que una regresión condicionando en `\(\text{X}_{i}\)`.

---

--

## Estimación

.hi[Pregunta]

&gt; Una gran pregunta aquí es cómo modelar y estimar mejor `\(p(\text{X}_{i})\)`...

--

.hi[Respuesta]

--

&gt; La respuesta a esto es inherentemente específica de la aplicación. Una creciente literatura empírica sugiere que un modelo logit para el puntaje de propensión con algunos términos polinomiales en covariables continuas funciona bien en la práctica...

---

--

## Aplicación

Entonces ya tiene algunos puntajes de propensión estimados `\(\hat{p}(\text{X}_{i})\)`. ¿Qué sigue?

--

.note[Opción 1] Condicionar vía .ul[regresión]

--

.note[Opción 1a] Use una .b[regresión para condicionar] en `\(p(\text{X}_{i})\)`, _es decir_,
$$
`\begin{align}
   \text{Y}_{i} = \alpha + \delta \text{D}_{i} + \beta p(\text{X}_{i}) + u_i \tag{1a}
\end{align}`
$$

--

.note[Opción 1b] Si creemos que los efectos del tratamiento son heterogéneos y pueden covariar con `\(\text{X}\)`, entonces podríamos querer también .b[interactuar] el tratamiento con `\(p(\text{X}_{i})\)`, _es decir_,
$$
`\begin{align}
   \text{Y}_{i} = \alpha + \delta_1 \text{D}_{i} + \delta_2 \text{D}_{i} p(\text{X}_{i}) + \beta p(\text{X}_{i}) + u_i \tag{1b}
\end{align}`
$$

---

--

## Heterogeneidad con regresión

Pensemos un poco más sobre los efectos heterogéneos del tratamiento en este contexto.
$$
`\begin{align}
  \text{Y}_{0i} &amp;= \alpha + \beta \text{X}_{i} + u_i \\
  \text{Y}_{1i} &amp;= \text{Y}_{0i} + \delta_1 + \delta_2 \text{X}_{i}
\end{align}`
$$
_es decir_, el efecto del tratamiento depende de `\(\text{X}_{i}\)`.

--

`\(\text{Y}_{i} = \text{D}_{i}\text{Y}_{1i} + \left( 1 - \text{D}_{i} \right) \text{Y}_{0i}\)`

--
.pad-left[
`\(= \text{D}_{i}\bigg( \text{Y}_{0i} + \delta_1 + \delta_2 \text{X}_{i} \bigg) + \left( 1 - \text{D}_{i} \right) \text{Y}_{0i}\)`
]

--
.pad-left[
`\(= \text{Y}_{0i} + \delta_1 \text{D}_{i} + \delta_2 \text{D}_{i} \text{X}_{i}\)`
]

--
.pad-left[
`\(= \alpha + \delta_1 \text{D}_{i} + \delta_2 \text{D}_{i} \text{X}_{i} + \beta \text{X}_{i} + u_i\)`
]

---

--

## Heterogeneidad

Esta es la ecuación final
$$
`\begin{align}
  \text{Y}_{i} = \alpha + \delta_1 \text{D}_{i} + \delta_2 \text{D}_{i} \text{X}_{i} + \beta \text{X}_{i} + u_i
\end{align}`
$$

--

sugiere que queremos `\(p(\text{X}_{i})\)` *y* `\(\text{D}_{i}p(\text{X}_{i})\)`, _es decir_,
$$
`\begin{align}
   \text{Y}_{i} = \alpha + \delta_1 \text{D}_{i} + \delta_2 \text{D}_{i} p(\text{X}_{i}) + \beta p(\text{X}_{i}) + u_i \tag{1b}
\end{align}`
$$

--

lo que produce
1. un .hi-slate[efecto del tratamiento específico del grupo] `\(\delta_1 + \delta_2 p(\text{X}_{i})\)` para cada `\(\text{X}_{i}\)`

2. un .hi-slate[efecto promedio del tratamiento] `\(\delta_1 + \delta_2 \overline{p}(\text{X}_{i})\)`

---

--

## Más flexibilidad

Motivamos los puntajes de propensión con el deseo de reducir la dimensionalidad y estimar/elegir/asumir menos parámetros.

--

Agregar `\(p(\text{X}_{i})\)` y `\(\text{D}_{i}p(\text{X}_{i})\)` como covariables en una .hi[regresión lineal] no agota del todo nuestro potencial para una estimación flexible/no paramétrica.

---

--

## Estratificación

.note[Opción 2] Estratificar en puntajes de propensión.

--

1. Divide el rango de `\(\hat{p}(\text{X}_{i})\)` en `\(K\)` bloques (_por ejemplo_, bloques de 0.05 de ancho).

1. Coloque cada observación en un bloque según su `\(\hat{p}(\text{X}_{i})\)`.

1. Calcule `\(\hat{\tau}_k\)` para cada bloque mediante la diferencia en medias.

1. Promedie los `\(\hat{\tau}_k\)` utilizando sus proporciones en la muestra, _es decir_,

$$
`\begin{align}
  \hat{\tau}_\text{Block} = \sum_{k = 1}^K  \hat{\tau}_k \dfrac{N_{1k} + N_{0k}}{N}
\end{align}`
$$

--

.note[Nota] La estratificación es similar al emparejamiento NN/kernel utilizando `\(p(\text{X}_{i})\)` como distancia.

---

--

## Selección de bloques

La estratificación en puntajes de propensión requiere definir bloques.

--

Un método común implica algunas iteraciones.

1. .hi[Elija bloques].

1. Verifica el .hi[equilibrio de las covariables] dentro de cada bloque..super[.pink[†]]

  - Si las covariables .pink[no están equilibradas], entonces divida sus bloques y repita.

  - Si las covariables están .pink[equilibradas], entonces detente.

.footnote[.pink[†] Tenga en cuenta las pruebas de hipótesis múltiples. Con muchas covariables y muchos bloques, es probable que encuentre relaciones estadísticamente significativas, incluso si en realidad están equilibradas.]

---

--

## Overlap

La estratificación enfatiza nuestro supuesto de overlaping, _es decir_, `\(0&lt;\mathop{\text{Pr}}\left(\text{D}_{i} | \text{X}_{i}\right)&lt;1\)`.

Si un bloque no contiene unidades tratadas/control, no podemos calcular `\(\hat{\tau}_k\)`.

--

.attn[Precaución] El modelo logit puede ocultar violaciones, ya que fuerza `\(0 &lt; \hat{p}(\text{X}_{i}) &lt; 1\)`.

--

.note[Práctica común] Hacer cumplir empíricamente la superposición:

- Elimine las unidades de control con `\(\hat{p}(\text{X}_{i})\)` por debajo del puntaje de propensión mínimo en el grupo tratado.

- Elimine las unidades tratadas con `\(\hat{p}(\text{X}_{i})\)` por encima del puntaje de propensión máximo en el grupo de control.

---

--

## Ponderación

.note[Opción 3] Ponderar las observaciones por el inverso del puntaje de propensión.

--

.hi[P] ¿Cómo tiene sentido ponderar por `\(1/\hat{p}(\text{X}_{i})\)`?

--

.qa[R] Consideremos a nuestro viejo (probablemente sesgado) amigo, la diferencia en medias, _es decir_,

$$
`\begin{align}
  \hat{\tau}_\text{DID} = \overline{\text{Y}}_\text{T} - \overline{\text{Y}}_\text{C} = \dfrac{\sum_i \text{D}_{i} \text{Y}_{i}}{\sum_i \text{D}_{i}} - \dfrac{\sum_i \left(1 - \text{D}_{i}\right) \text{Y}_{i}}{\sum_i \left(1 - \text{D}_{i}\right)}
\end{align}`
$$

--

del cual hemos discutido que está sesgado debido a la selección en el tratamiento, _es decir_,

$$
`\begin{align}
  \mathop{E}\left[ \text{Y}_{0i} | \text{D}_{i} = 1 \right] \neq \mathop{E}\left[ \text{Y}_{0i} \right]
\end{align}`
$$

---

--

## Ponderación, justificada

Supongamos que conocemos `\(p(\text{X}_{i})\)` y ponderamos cada individuo .hi-pink[tratado] por `\(1/p(\text{X}_{i})\)`

--

`\(\mathop{E}\left[ \dfrac{\text{D}_{i} \text{Y}_{i}}{p(\text{X}_{i})} \right]\)`

--
 `\(= \mathop{E}\left[ \dfrac{\text{D}_{i}\left(\text{D}_{i}\text{Y}_{1i} + (1-\text{D}_{i})\text{Y}_{0i}\right)}{p(\text{X}_{i})} \right]\)`

--
 `\(= \mathop{E}\left[ \dfrac{\text{D}_{i} \text{Y}_{1i}}{p(\text{X}_{i})} \right]\)`

--
&lt;br&gt;&lt;br&gt;  `\(= \mathop{E}\!\bigg( \mathop{E}\left[ \dfrac{\text{D}_{i}\text{Y}_{1i}}{p(\text{X}_{i})} \;\middle|\; \text{X}_{i} \right] \bigg)\)`

--
 `\(= \mathop{E}\!\bigg( \dfrac{\mathop{E}\left[ \text{D}_{i} \mid \text{X}_{i} \right] \mathop{E}\left[ \text{Y}_{1i} \mid \text{X}_{i} \right]}{p(\text{X}_{i})} \bigg)\)`

--
&lt;br&gt;&lt;br&gt;  `\(= \mathop{E}\!\bigg( \dfrac{p(\text{X}_{i}) \mathop{E}\left[ \text{Y}_{1i} \mid \text{X}_{i} \right]}{p(\text{X}_{i})} \bigg)\)`

--
 `\(= \mathop{E}\!\bigg( \mathop{E}\left[ \text{Y}_{1i} \mid \text{X}_{i} \right] \bigg)\)`

--
 `\(\color{#e64173}{= \mathop{E}\left[ \text{Y}_{1i} \right]}\)`

--

Similarmente, los .hi-purple[controles] ponderados individuales por `\(1/(1-p(\text{X}_{i}))\)` caen en:
$$
`\begin{align}
  \mathop{E}\left[ \dfrac{(1-\text{D}_{i})\text{Y}_{i}}{1-p(\text{X}_{i})} \right] = \color{#6A5ACD}{\mathop{E}\left[ \text{Y}_{0i} \right]}
\end{align}`
$$
---
## Ponderación: El estimador

Así, podemos estimar un efecto del tratamiento insesgado mediante
$$
`\begin{align}
  \hat{\tau}_{p\text{Weight}} = \dfrac{1}{N} \sum_{i=1}^N \left[ \dfrac{\text{D}_{i}\text{Y}_{i}}{p(\text{X}_{i})} - \dfrac{(1-\text{D}_{i})\text{Y}_{i}}{1 - p(\text{X}_{i})} \right]
\end{align}`
$$

--

.note[Intuición] Intentamos superar el sesgo de selección, _así como,_, dividuos tratados eran más propensos a ser tratados en función de `\(\text{X}_{i}\)`—pproduciendo mayores `\(p(\text{X}_{i})\)`.

--

Queremos volver a una variación *tan buena como aleatoria* en el tratamiento.

Así que aumentamos el peso de los .pink[(**1**)  .hi-pink[tratados] con bajo] `\(\color{#e64173}{p(\text{X}_{i})}\)` y las observaciones que son .purple[(**2**) .hi-purple[controles] con alto] `\(\color{#6A5ACD}{p(\text{X}_{i})}\)`.

Aquí tienes la traducción con el LaTeX y las pausas de Markdown intactas:

---

## Ponderación: El ejemplo

Supongamos que para algún individuo `\(i\)`, `\(p(\text{X}_{i}) = 0.80\)`.

--

Este puntaje de propensión dice que alguien con este conjunto de `\(\text{X}_{i}\)` tenía cuatro veces más probabilidades de ser .hi-pink[tratado] que .hi-purple[control].

--

Nuestros pesos corrigen este desequilibrio para cada `\(\text{X}_{i}\)`.

--

- Si `\(i\)` es .hi-pink[tratado], entonces su peso es `\(1/p(\text{X}_{i}) = 1/0.80 = 1.25\)`

--

- Si `\(i\)` es .hi-purple[control], entonces su peso es `\(1/(1-p(\text{X}_{i})) = 1/(1-0.80) = 5\)`

--

Y adivina qué es `\(5/1.25\)`...

--
 ¡$4$!

--
 Este esquema de ponderación nos devuelve a la representación equitativa para cada conjunto de `\(\text{X}_{i}\)`.

---

## Ponderación: Último problema

.note[Problema práctico] Nada garantiza que `\(\sum_i \hat{p}(\text{X}_{i}) = 1\)`.

--

.note[Solución] Normalizar los pesos por su suma total.

--

Aplicando los puntajes de propensión normalizados (y estimados)
$$
`\begin{align}
  \hat{\tau}_{p\text{Weight}} = \sum_{i=1}^N \dfrac{ \dfrac{\text{D}_{i}\text{Y}_{i}}{\hat{p}(\text{X}_{i})} }{\sum_{i} \dfrac{\text{D}_{i}}{\hat{p}(\text{X}_{i})}} -
  \sum_{i=1}^N \dfrac{ \dfrac{(1-\text{D}_{i})\text{Y}_{i}}{1-\hat{p}(\text{X}_{i})} }{\sum_{i} \dfrac{(1-\text{D}_{i})}{1-\hat{p}(\text{X}_{i})}}
\end{align}`
$$

--

Hirano, Imbens y Ridder (2003) sugieren que este estimador es eficiente.

---

name: two
## ¿Por qué elegir uno?

No hay nada especial en los promedios ponderados—la regresión también puede ponderar.

Así, una .hi-slate[estimación basada en regresión]
$$
`\begin{align}
  \text{Y}_{i} = \alpha + \text{X}_{i}\beta + \tau \text{D}_{i} + u_i
\end{align}`
$$
--
con .hi-slate[pesos]
$$
`\begin{align}
  w_i = \sqrt{\dfrac{\text{D}_{i}}{\hat{p}(\text{X}_{i})} + \dfrac{(1-\text{D}_{i})}{1-\hat{p}(\text{X}_{i})}}
\end{align}`
$$
--
ofrece una propiedad *doblemente robusta*—tienes dos oportunidades de acertar: `\(p(\text{X}_{i})\)` o la especificación de la regresión.

---

## ¿Por qué elegir uno? Parte dos

Un método alternativo, doblemente robusto, combina la estratificación por puntaje de propensión con la regresión.

--

.note[Paso 1] Para cada bloque `\(k\)`, ejecutamos la regresión
$$
`\begin{align}
  \text{Y}_{i} = \alpha_k + \text{X}_{i} \beta_k + \tau_k \text{D}_{i} + u_i
\end{align}`
$$

--

.note[Paso 2] Agregamos las estimaciones del efecto del tratamiento a nivel de bloque
$$
`\begin{align}
  \hat{\tau} = \sum_{k=1}^K \hat{\tau}_k \dfrac{N_{1k} + N_{0k}}{N}
\end{align}`
$$

---

## Requisitos principales

No te dejes atrapar (demasiado) por los adornos.

Todavía tenemos dos .hi-slate[requisitos] principales para que cualquiera de estos métodos funcione.

--

1. ¿Es verdadera la .hi-blue[hipotesis de independencia condicional]?

--

2. ¿Tenemos .hi-slate[overlaping] entre las unidades de tratamiento y control?

--

Podemos buscar evidencia de (.hi-slate[2]) en los datos—particularmente si estamos utilizando métodos de puntaje de propensión..super[.pink[†]]

¿Cómo? Grafica las distribuciones de `\(p(\text{X}_{i})\)` para .hi-pink[T] y .hi-purple[C].

.footnote[.pink[†] Verificar la superposición en el espacio de X puede ser difícil a medida que las dimensiones de X se expanden.]

---
layout: false
class: clear, middle

Overlap perdidos en `\(p(\text{X}_{i})\)`
&lt;img src="ClassPMS_files/figure-html/ex-no-overlap-1.svg" style="display: block; margin: auto;" /&gt;
---
class: clear, middle

Overlap autentico (forzado) en `\(p(\text{X}_{i})\)`
&lt;img src="ClassPMS_files/figure-html/ex-overlap-p-1.svg" style="display: block; margin: auto;" /&gt;
---
class: clear, middle

Modelo logit basado en `\(\hat{p}(\text{X}_{i})\)` ocultando parte del overlap que falta en `\(p(\text{X}_{i})\)`
&lt;img src="ClassPMS_files/figure-html/ex-no-overlap-logit-1.svg" style="display: block; margin: auto;" /&gt;
---
class: clear, middle

El overlaping en una dimensión no lo garantiza en dos dimensiones.
&lt;br&gt;.smallest[.note[Note] el sombreado nos dice .hi-slate[la distribución del tratamiento] .gw[.grey-light[l]**Blanco**.grey-light[l]]=0% y .hi-pink[Rosado]=100%.]
&lt;img src="ClassPMS_files/figure-html/ex-overlap2-1.svg" style="display: block; margin: auto;" /&gt;

---
class: inverse
# Bibliografía

<svg aria-hidden="true" role="img" viewBox="0 0 384 512" style="height:1em;width:0.75em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm97 289c9.4-9.4 9.4-24.6 0-33.9s-24.6-9.4-33.9 0L79 303c-9.4 9.4-9.4 24.6 0 33.9l48 48c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-31-31 31-31zM257 255c-9.4-9.4-24.6-9.4-33.9 0s-9.4 24.6 0 33.9l31 31-31 31c-9.4 9.4-9.4 24.6 0 33.9s24.6 9.4 33.9 0l48-48c9.4-9.4 9.4-24.6 0-33.9l-48-48z"/></svg> Recursos de Rubin, E. (2024) *Econometrics PhD Lectures class* (Todos los créditos). MIMEO

<svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M96 0C43 0 0 43 0 96V416c0 53 43 96 96 96H384h32c17.7 0 32-14.3 32-32s-14.3-32-32-32V384c17.7 0 32-14.3 32-32V32c0-17.7-14.3-32-32-32H384 96zm0 384H352v64H96c-17.7 0-32-14.3-32-32s14.3-32 32-32zm32-240c0-8.8 7.2-16 16-16H336c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16zm16 48H336c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16s7.2-16 16-16z"/></svg> Angrist, J. D., &amp; Pischke, J. S. (2009). *Mostly harmless econometrics: An empiricist's companion*. Princeton university press.

<svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M96 0C43 0 0 43 0 96V416c0 53 43 96 96 96H384h32c17.7 0 32-14.3 32-32s-14.3-32-32-32V384c17.7 0 32-14.3 32-32V32c0-17.7-14.3-32-32-32H384 96zm0 384H352v64H96c-17.7 0-32-14.3-32-32s14.3-32 32-32zm32-240c0-8.8 7.2-16 16-16H336c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16zm16 48H336c8.8 0 16 7.2 16 16s-7.2 16-16 16H144c-8.8 0-16-7.2-16-16s7.2-16 16-16z"/></svg> Wooldridge, J. M. (2015). *Introductory econometrics: A modern approach*. Cengage learning.


---
name: adios
class: middle, inverse

.pull-left[
# **¡Gracias!**
&lt;br/&gt;
## Econometría

### Seguimos aprendiendo
]

.pull-right[
.right[
&lt;img style="border-radius: 50%;"
src="https://avatars.githubusercontent.com/u/39503983?v=4"
width="150px" /&gt;

[<svg aria-hidden="true" role="img" viewBox="0 0 640 512" style="height:1em;width:1.25em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M579.8 267.7c56.5-56.5 56.5-148 0-204.5c-50-50-128.8-56.5-186.3-15.4l-1.6 1.1c-14.4 10.3-17.7 30.3-7.4 44.6s30.3 17.7 44.6 7.4l1.6-1.1c32.1-22.9 76-19.3 103.8 8.6c31.5 31.5 31.5 82.5 0 114L422.3 334.8c-31.5 31.5-82.5 31.5-114 0c-27.9-27.9-31.5-71.8-8.6-103.8l1.1-1.6c10.3-14.4 6.9-34.4-7.4-44.6s-34.4-6.9-44.6 7.4l-1.1 1.6C206.5 251.2 213 330 263 380c56.5 56.5 148 56.5 204.5 0L579.8 267.7zM60.2 244.3c-56.5 56.5-56.5 148 0 204.5c50 50 128.8 56.5 186.3 15.4l1.6-1.1c14.4-10.3 17.7-30.3 7.4-44.6s-30.3-17.7-44.6-7.4l-1.6 1.1c-32.1 22.9-76 19.3-103.8-8.6C74 372 74 321 105.5 289.5L217.7 177.2c31.5-31.5 82.5-31.5 114 0c27.9 27.9 31.5 71.8 8.6 103.9l-1.1 1.6c-10.3 14.4-6.9 34.4 7.4 44.6s34.4 6.9 44.6-7.4l1.1-1.6C433.5 260.8 427 182 377 132c-56.5-56.5-148-56.5-204.5 0L60.2 244.3z"/></svg> Syllabus/ Curso](https://ignaciomsarmiento.github.io/teaching/UniNorte/Syllabus__Ciencia_de_Datos_TDE.pdf)&lt;br/&gt;
[<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> @keynes37](https://twitter.com/keynes37)&lt;br/&gt;
[<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M64 112c-8.8 0-16 7.2-16 16v22.1L220.5 291.7c20.7 17 50.4 17 71.1 0L464 150.1V128c0-8.8-7.2-16-16-16H64zM48 212.2V384c0 8.8 7.2 16 16 16H448c8.8 0 16-7.2 16-16V212.2L322 328.8c-38.4 31.5-93.7 31.5-132 0L48 212.2zM0 128C0 92.7 28.7 64 64 64H448c35.3 0 64 28.7 64 64V384c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64V128z"/></svg> cayanes@uninorte.edu.co](mailto:cayanes@uninorte.edu.co)
]
]


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
